{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-7Tx7R-Q8m-A"
      },
      "outputs": [],
      "source": [
        "#모듈 로딩\n",
        "# Model 관련\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "\n",
        "# Data 및 시각화 관련\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "D3Am_70x_W8R",
        "outputId": "151ab7a1-4cca-469c-cef9-b2a6492ca282"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HU9CWFlL8m-B"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, features, targets):\n",
        "        self.features = features\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.targets[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UR-3ZZBL8m-B"
      },
      "outputs": [],
      "source": [
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, output_size):\n",
        "        super(MLPModel, self).__init__()\n",
        "\n",
        "        # 은닉층들을 nn.ModuleList로 관리\n",
        "        layers = []\n",
        "        in_features = input_size\n",
        "\n",
        "        for hidden_size in hidden_sizes:\n",
        "            layers.append(nn.Linear(in_features, hidden_size))\n",
        "            layers.append(nn.ReLU())  # 활성화 함수로 ReLU 추가\n",
        "            in_features = hidden_size  # 다음 레이어의 입력 크기는 현재 레이어의 출력 크기\n",
        "\n",
        "        # Dropout과 마지막 출력층 추가\n",
        "        layers.append(nn.Dropout(0.3))  # Dropout 추가\n",
        "        layers.append(nn.Linear(in_features, output_size))\n",
        "\n",
        "        self.network = nn.Sequential(*layers)  # Sequential로 레이어 묶음\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rljkkeOb8m-C",
        "outputId": "9868efe4-e42e-4e44-f83e-eecdb30d5baa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>know intj tool use interaction people excuse a...</td>\n",
              "      <td>INTJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rap music ehh opp yeah know valid well know fa...</td>\n",
              "      <td>INTJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>preferably p hd low except wew lad video p min...</td>\n",
              "      <td>INTJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>drink like wish could drink red wine give head...</td>\n",
              "      <td>INTJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>space program ah bad deal meing freelance max ...</td>\n",
              "      <td>INTJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106062</th>\n",
              "      <td>stay frustrate world life want take long nap w...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106063</th>\n",
              "      <td>fizzle around time mention sure mistake thing ...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106064</th>\n",
              "      <td>schedule modify hey w intp strong wing underst...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106065</th>\n",
              "      <td>enfj since january busy schedule able spend li...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106066</th>\n",
              "      <td>feel like men good problem tell parent want te...</td>\n",
              "      <td>INFP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106067 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    posts  type\n",
              "0       know intj tool use interaction people excuse a...  INTJ\n",
              "1       rap music ehh opp yeah know valid well know fa...  INTJ\n",
              "2       preferably p hd low except wew lad video p min...  INTJ\n",
              "3       drink like wish could drink red wine give head...  INTJ\n",
              "4       space program ah bad deal meing freelance max ...  INTJ\n",
              "...                                                   ...   ...\n",
              "106062  stay frustrate world life want take long nap w...  INFP\n",
              "106063  fizzle around time mention sure mistake thing ...  INFP\n",
              "106064  schedule modify hey w intp strong wing underst...  INFP\n",
              "106065  enfj since january busy schedule able spend li...  INFP\n",
              "106066  feel like men good problem tell parent want te...  INFP\n",
              "\n",
              "[106067 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mbti_df=pd.read_csv('../data/MBTI.csv')\n",
        "mbti_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "WczpN3cw8m-C",
        "outputId": "69c61032-43ec-4237-9016-c93dedf0311b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>type</th>\n",
              "      <th>ei_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>know intj tool use interaction people excuse a...</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rap music ehh opp yeah know valid well know fa...</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>preferably p hd low except wew lad video p min...</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>drink like wish could drink red wine give head...</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>space program ah bad deal meing freelance max ...</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106062</th>\n",
              "      <td>stay frustrate world life want take long nap w...</td>\n",
              "      <td>INFP</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106063</th>\n",
              "      <td>fizzle around time mention sure mistake thing ...</td>\n",
              "      <td>INFP</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106064</th>\n",
              "      <td>schedule modify hey w intp strong wing underst...</td>\n",
              "      <td>INFP</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106065</th>\n",
              "      <td>enfj since january busy schedule able spend li...</td>\n",
              "      <td>INFP</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106066</th>\n",
              "      <td>feel like men good problem tell parent want te...</td>\n",
              "      <td>INFP</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106067 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    posts  type  ei_type\n",
              "0       know intj tool use interaction people excuse a...  INTJ        1\n",
              "1       rap music ehh opp yeah know valid well know fa...  INTJ        1\n",
              "2       preferably p hd low except wew lad video p min...  INTJ        1\n",
              "3       drink like wish could drink red wine give head...  INTJ        1\n",
              "4       space program ah bad deal meing freelance max ...  INTJ        1\n",
              "...                                                   ...   ...      ...\n",
              "106062  stay frustrate world life want take long nap w...  INFP        1\n",
              "106063  fizzle around time mention sure mistake thing ...  INFP        1\n",
              "106064  schedule modify hey w intp strong wing underst...  INFP        1\n",
              "106065  enfj since january busy schedule able spend li...  INFP        1\n",
              "106066  feel like men good problem tell parent want te...  INFP        1\n",
              "\n",
              "[106067 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mbti_df['ei_type']=mbti_df['type'].apply(lambda x: 1 if 'I' in str(x) else 0)  # 'I'면 1, 'E'면 0\n",
        "mbti_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "UOpHsYhN-Yda",
        "outputId": "6e7fcc92-dccb-4a0b-d2cc-91b6b9eadca3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ei_type\n",
              "0    5000\n",
              "1    5000\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r_sampled_df = mbti_df.groupby('ei_type', group_keys=False).apply(lambda x: x.sample(n=5000, random_state=42))\n",
        "r_sampled_df['ei_type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rsqsKieeRUO0"
      },
      "outputs": [],
      "source": [
        "r_sampled_df['ei_type'] = r_sampled_df['type'].apply(lambda x: 1 if 'E' in x else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vNp64ZBH8m-D"
      },
      "outputs": [],
      "source": [
        "result = pd.DataFrame(columns=['posts','ei_type'] )\n",
        "for index, row in r_sampled_df.iterrows():\n",
        "    # 각 행의 단어를 분리\n",
        "    features = row['posts'].split()\n",
        "    # 해당 단어에 맞는 타겟 값 생성\n",
        "    targets = [row['ei_type']] * len(features)\n",
        "\n",
        "    # 결과 데이터프레임에 추가\n",
        "    dfs = pd.DataFrame({'posts' : features, 'ei_type':targets})\n",
        "    result = pd.concat([result, dfs], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4PYLDFAH-P5b"
      },
      "outputs": [],
      "source": [
        "feature=r_sampled_df['posts'].values\n",
        "target=r_sampled_df['ei_type'].astype('float64').values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aVxvI7nA8m-D"
      },
      "outputs": [],
      "source": [
        "#벡터화\n",
        "tfidf = TfidfVectorizer(max_features=5000)  # 최대 5000개의 단어만 사용\n",
        "X = tfidf.fit_transform(feature)\n",
        "\n",
        "#Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "#텐서화\n",
        "X_train_tensor = torch.FloatTensor(X_train.toarray())\n",
        "X_test_tensor = torch.FloatTensor(X_test.toarray())\n",
        "y_train_tensor = torch.LongTensor(y_train)\n",
        "y_test_tensor = torch.LongTensor(y_test)\n",
        "x_val_tensor = torch.FloatTensor(X_val.toarray()).to(DEVICE)\n",
        "y_val_tensor = torch.LongTensor(y_val).to(DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zfgbmhDn_dXC"
      },
      "outputs": [],
      "source": [
        "## models 폴더 아래 프로젝트 폴더 아래 모델 파일저장\n",
        "import os\n",
        "\n",
        "# 저장 경로\n",
        "SAVE_PATH = './models/mbti/'\n",
        "# 저장 파일명\n",
        "SAVE_FILE = 'ei_model_train_wbs.pth'\n",
        "# 저장 모델구조 및 파라미터 모두 저장\n",
        "SAVE_MODEL = 'ei_model_all.pth'\n",
        "\n",
        "if not os.path.exists(SAVE_PATH):\n",
        "    os.makedirs(SAVE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2n-S2nl58m-E"
      },
      "outputs": [],
      "source": [
        "train_dataset = MyDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = MyDataset(X_test_tensor, y_test_tensor)\n",
        "val_dataset = MyDataset(x_val_tensor, y_val_tensor)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x7U49gL8m-E",
        "outputId": "c6e76112-0bc9-4de0-9c31-60661d572d46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\desktop\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "input_size = 5000\n",
        "hidden_sizes = [1000, 500, 300, 100, 50]\n",
        "output_size = 1  # 이진 분류\n",
        "\n",
        "model = MLPModel(input_size, hidden_sizes, output_size)\n",
        "model.to(DEVICE)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler=lr_scheduler.ReduceLROnPlateau(optimizer,mode='max',patience=10,verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX123ZGf8m-E",
        "outputId": "34ead474-90a2-4a7a-a307-71087af6b9f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLPModel(\n",
            "  (network): Sequential(\n",
            "    (0): Linear(in_features=5000, out_features=1000, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1000, out_features=500, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=500, out_features=300, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=300, out_features=100, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
            "    (9): ReLU()\n",
            "    (10): Dropout(p=0.3, inplace=False)\n",
            "    (11): Linear(in_features=50, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1OQ7fxt8m-F",
        "outputId": "ad44552c-f252-495c-c496-87bfcab9d482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Loss: 0.6599, F1: 0.6986\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [2/100], Loss: 0.2850, F1: 0.8889\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [3/100], Loss: 0.1394, F1: 0.9591\n",
            "scheduler.num_bad_epochs: 2 scheduler.patience: 10\n",
            "Epoch [4/100], Loss: 0.0774, F1: 0.9815\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [5/100], Loss: 0.0437, F1: 0.9908\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [6/100], Loss: 0.0255, F1: 0.9961\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [7/100], Loss: 0.0129, F1: 0.9981\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [8/100], Loss: 0.0098, F1: 0.9986\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [9/100], Loss: 0.0063, F1: 0.9991\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [10/100], Loss: 0.0030, F1: 0.9995\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [11/100], Loss: 0.0011, F1: 0.9998\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [12/100], Loss: 0.0004, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [13/100], Loss: 0.0003, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [14/100], Loss: 0.0002, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [15/100], Loss: 0.0001, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [16/100], Loss: 0.0001, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [17/100], Loss: 0.0001, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [18/100], Loss: 0.0001, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [19/100], Loss: 0.0001, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [20/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [21/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [22/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [23/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [24/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [25/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [26/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [27/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 2 scheduler.patience: 10\n",
            "Epoch [28/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [29/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [30/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [31/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [32/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [33/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [34/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [35/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [36/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [37/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 2 scheduler.patience: 10\n",
            "Epoch [38/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [39/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [40/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 2 scheduler.patience: 10\n",
            "Epoch [41/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [42/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [43/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [44/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [45/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 2 scheduler.patience: 10\n",
            "Epoch [46/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [47/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [48/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [49/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [50/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [51/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [52/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [53/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [54/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [55/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [56/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [57/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [58/100], Loss: 0.0126, F1: 0.9973\n",
            "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
            "Epoch [59/100], Loss: 0.1928, F1: 0.9501\n",
            "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
            "Epoch [60/100], Loss: 0.0313, F1: 0.9918\n",
            "scheduler.num_bad_epochs: 2 scheduler.patience: 10\n",
            "Epoch [61/100], Loss: 0.0060, F1: 0.9991\n",
            "scheduler.num_bad_epochs: 3 scheduler.patience: 10\n",
            "Epoch [62/100], Loss: 0.0013, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 4 scheduler.patience: 10\n",
            "Epoch [63/100], Loss: 0.0004, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 5 scheduler.patience: 10\n",
            "Epoch [64/100], Loss: 0.0001, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 6 scheduler.patience: 10\n",
            "Epoch [65/100], Loss: 0.0001, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 7 scheduler.patience: 10\n",
            "Epoch [66/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 8 scheduler.patience: 10\n",
            "Epoch [67/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 9 scheduler.patience: 10\n",
            "Epoch [68/100], Loss: 0.0000, F1: 1.0000\n",
            "scheduler.num_bad_epochs: 10 scheduler.patience: 10\n",
            "10 EPOCH 성능 개선 없어서 조기 종료\n",
            "Accuracy: 0.8035\n",
            "F1 Score: 0.8004\n"
          ]
        }
      ],
      "source": [
        "# 7. 모델 학습\n",
        "epochs = 100\n",
        "LOSS_HISTORY, SCORE_HISTORY = [[],[]],[[],[]]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    train_pred = []\n",
        "    train_true = []\n",
        "\n",
        "    for features, targets in train_loader:\n",
        "        features, targets = features.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(features).view(-1)\n",
        "        predicted = torch.round(torch.sigmoid(outputs))\n",
        "        loss = criterion(outputs, targets.float())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        train_pred.extend(predicted.detach().cpu().numpy())\n",
        "        train_true.extend(targets.detach().cpu().numpy())\n",
        "\n",
        "    train_f1 = f1_score(train_pred, train_true)\n",
        "    avg_loss_train = epoch_loss / len(train_loader)\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss_train:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "    LOSS_HISTORY[0].append(avg_loss_train)\n",
        "    SCORE_HISTORY[0].append(train_f1)\n",
        "\n",
        "    #검증\n",
        "    model.eval()\n",
        "\n",
        "    v_pred = []\n",
        "    v_true = []\n",
        "    v_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features, targets in val_loader:\n",
        "            outputs = model(features).view(-1)\n",
        "            predicted = torch.round(torch.sigmoid(outputs))  # 시그모이드 함수로 확률 변환\n",
        "            v_pred.extend(predicted.cpu().numpy())\n",
        "            v_true.extend(targets.cpu().numpy())\n",
        "            loss = criterion(outputs, targets.float())\n",
        "            v_loss += loss.item()\n",
        "\n",
        "        val_f1 = f1_score(train_pred, train_true)\n",
        "        avg_loss_val = epoch_loss / len(train_loader)\n",
        "\n",
        "        LOSS_HISTORY[1].append(avg_loss_val)\n",
        "        SCORE_HISTORY[1].append(val_f1)\n",
        "\n",
        "    #최적화 스케줄러 인스턴스 업데이트\n",
        "    scheduler.step(loss)\n",
        "    print(f'scheduler.num_bad_epochs: {scheduler.num_bad_epochs}',end=' ')\n",
        "    print(f'scheduler.patience: {scheduler.patience}')\n",
        "\n",
        "    if len(SCORE_HISTORY[1]) == 1:\n",
        "\n",
        "        # 첫번째라서 무조건 모델 파라미터 저장\n",
        "        torch.save(model.state_dict(),SAVE_PATH+SAVE_FILE)\n",
        "\n",
        "        # 모델 전체 저장\n",
        "        torch.save(model,SAVE_PATH+SAVE_MODEL)\n",
        "\n",
        "    else:\n",
        "        if SCORE_HISTORY[1][-1] >= max(SCORE_HISTORY[1]):\n",
        "            # torch.save(model.state_dict(),f'{SAVE_PATH}{SAVE_FILE}_{epoch}_{LOSS_HISTORY[1][-1]}')\n",
        "            torch.save(model.state_dict(),SAVE_PATH+SAVE_FILE)\n",
        "            # 모델 전체 저장\n",
        "            torch.save(model,SAVE_PATH+SAVE_MODEL)\n",
        "\n",
        "    #손실 감소(성능 개선) 안 되는 경우 조기 종료\n",
        "    if scheduler.num_bad_epochs >= scheduler.patience:\n",
        "        print(f'{scheduler.patience} EPOCH 성능 개선 없어서 조기 종료')\n",
        "        break\n",
        "\n",
        "#모델 평가\n",
        "model.eval()\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for features, targets in test_loader:\n",
        "        features, targets = features.to(DEVICE), targets.to(DEVICE)\n",
        "        outputs = model(features).view(-1)\n",
        "        predicted = torch.round(torch.sigmoid(outputs))\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "        y_true.extend(targets.cpu().numpy())\n",
        "\n",
        "# 성능 지표 계산\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DufDz74rAoPZ"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 186. GiB for an array with shape (5000432, 5000) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m r_labels \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mei_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      4\u001b[0m r_X \u001b[38;5;241m=\u001b[39m tfidf\u001b[38;5;241m.\u001b[39mfit_transform(r_posts)\n\u001b[1;32m----> 5\u001b[0m r_X_test_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[43mr_X\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m      6\u001b[0m r_y_train_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(r_labels)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m      7\u001b[0m r_val_dataset \u001b[38;5;241m=\u001b[39m MyDataset(x_val_tensor, y_val_tensor)\n",
            "File \u001b[1;32mc:\\Users\\desktop\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1051\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1050\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1051\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\desktop\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\scipy\\sparse\\_base.py:1298\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 186. GiB for an array with shape (5000432, 5000) and data type float64"
          ]
        }
      ],
      "source": [
        "#텍스트와 라벨 데이터 준비\n",
        "r_posts = result['posts'].values\n",
        "r_labels = result['ei_type'].astype('float64').values\n",
        "r_X = tfidf.fit_transform(r_posts)\n",
        "r_X_test_tensor = torch.FloatTensor(r_X.toarray()).to(DEVICE)\n",
        "r_y_train_tensor = torch.LongTensor(r_labels).to(DEVICE)\n",
        "r_val_dataset = MyDataset(x_val_tensor, y_val_tensor)\n",
        "r_val_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n",
        "model.eval()\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for features, targets in r_val_loader:\n",
        "        outputs = model(features).view(-1)\n",
        "        predicted = torch.round(torch.sigmoid(outputs))  # 시그모이드 함수로 확률 변환\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "        y_true.extend(targets.cpu().numpy())\n",
        "\n",
        "#성능 지표 계산\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "muqqPzIH8m-F"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#학습 결과 확인(학습과 검증의 Loss, 성능지표 변화 확인) w. 시각화\n",
        "\n",
        "th=len(SCORE_HISTORY[1])\n",
        "fg,axes=plt.subplots(1,2,figsize=(10,5),sharey=True)\n",
        "axes[0].plot(range(1,th+1),LOSS_HISTORY[0][:th],label='Train')\n",
        "axes[0].plot(range(1,th+1),LOSS_HISTORY[1][:th],label='Val')\n",
        "axes[0].set_ylim([0.5,0.8])\n",
        "axes[0].grid()\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(range(1,th+1),SCORE_HISTORY[0][:th],label='Train')\n",
        "axes[1].plot(range(1,th+1),SCORE_HISTORY[1][:th],label='Val')\n",
        "axes[1].grid()\n",
        "\n",
        "axes[1].legend\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9V74OAA8m-F"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
