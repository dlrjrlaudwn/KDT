{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모듈 로딩\n",
    "# Model 관련\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.optim.lr_scheduler as lr_scheduler \n",
    "\n",
    "\n",
    "# Data 및 시각화 관련\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MLPModel, self).__init__()\n",
    "        \n",
    "        # 은닉층들을 nn.ModuleList로 관리\n",
    "        layers = []\n",
    "        in_features = input_size\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(in_features, hidden_size))\n",
    "            layers.append(nn.ReLU())  # 활성화 함수로 ReLU 추가\n",
    "            in_features = hidden_size  # 다음 레이어의 입력 크기는 현재 레이어의 출력 크기\n",
    "        \n",
    "        # Dropout과 마지막 출력층 추가\n",
    "        layers.append(nn.Dropout(0.3))  # Dropout 추가\n",
    "        layers.append(nn.Linear(in_features, output_size))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)  # Sequential로 레이어 묶음\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know intj tool use interaction people excuse a...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap music ehh opp yeah know valid well know fa...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preferably p hd low except wew lad video p min...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drink like wish could drink red wine give head...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>space program ah bad deal meing freelance max ...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106062</th>\n",
       "      <td>stay frustrate world life want take long nap w...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106063</th>\n",
       "      <td>fizzle around time mention sure mistake thing ...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106064</th>\n",
       "      <td>schedule modify hey w intp strong wing underst...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106065</th>\n",
       "      <td>enfj since january busy schedule able spend li...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106066</th>\n",
       "      <td>feel like men good problem tell parent want te...</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106067 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    posts  type\n",
       "0       know intj tool use interaction people excuse a...  INTJ\n",
       "1       rap music ehh opp yeah know valid well know fa...  INTJ\n",
       "2       preferably p hd low except wew lad video p min...  INTJ\n",
       "3       drink like wish could drink red wine give head...  INTJ\n",
       "4       space program ah bad deal meing freelance max ...  INTJ\n",
       "...                                                   ...   ...\n",
       "106062  stay frustrate world life want take long nap w...  INFP\n",
       "106063  fizzle around time mention sure mistake thing ...  INFP\n",
       "106064  schedule modify hey w intp strong wing underst...  INFP\n",
       "106065  enfj since january busy schedule able spend li...  INFP\n",
       "106066  feel like men good problem tell parent want te...  INFP\n",
       "\n",
       "[106067 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_df=pd.read_csv('../data/MBTI.csv')\n",
    "mbti_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>type</th>\n",
       "      <th>E/I_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know intj tool use interaction people excuse a...</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap music ehh opp yeah know valid well know fa...</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preferably p hd low except wew lad video p min...</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drink like wish could drink red wine give head...</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>space program ah bad deal meing freelance max ...</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106062</th>\n",
       "      <td>stay frustrate world life want take long nap w...</td>\n",
       "      <td>INFP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106063</th>\n",
       "      <td>fizzle around time mention sure mistake thing ...</td>\n",
       "      <td>INFP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106064</th>\n",
       "      <td>schedule modify hey w intp strong wing underst...</td>\n",
       "      <td>INFP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106065</th>\n",
       "      <td>enfj since january busy schedule able spend li...</td>\n",
       "      <td>INFP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106066</th>\n",
       "      <td>feel like men good problem tell parent want te...</td>\n",
       "      <td>INFP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106067 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    posts  type  E/I_type\n",
       "0       know intj tool use interaction people excuse a...  INTJ         1\n",
       "1       rap music ehh opp yeah know valid well know fa...  INTJ         1\n",
       "2       preferably p hd low except wew lad video p min...  INTJ         1\n",
       "3       drink like wish could drink red wine give head...  INTJ         1\n",
       "4       space program ah bad deal meing freelance max ...  INTJ         1\n",
       "...                                                   ...   ...       ...\n",
       "106062  stay frustrate world life want take long nap w...  INFP         1\n",
       "106063  fizzle around time mention sure mistake thing ...  INFP         1\n",
       "106064  schedule modify hey w intp strong wing underst...  INFP         1\n",
       "106065  enfj since january busy schedule able spend li...  INFP         1\n",
       "106066  feel like men good problem tell parent want te...  INFP         1\n",
       "\n",
       "[106067 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_df['E/I_type']=mbti_df['type'].apply(lambda x: 1 if 'I' in x else 0)  # 'I'면 1, 'E'면 0\n",
    "mbti_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106067,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df=mbti_df['posts'].str.replace(' ',',')\n",
    "feature_df=feature_df.values\n",
    "feature_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106067,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df=mbti_df['E/I_type'].values\n",
    "target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#벡터화\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # 최대 5000개의 단어만 사용\n",
    "X = tfidf.fit_transform(feature_df)\n",
    "\n",
    "# 3. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# PyTorch 텐서로 변환\n",
    "X_train_tensor = torch.FloatTensor(X_train.toarray())\n",
    "X_test_tensor = torch.FloatTensor(X_test.toarray())\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "y_test_tensor = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = MyDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\desktop\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_size = 5000\n",
    "hidden_sizes = [1000, 500, 300, 100, 50]  \n",
    "output_size = 1  # 이진 분류\n",
    "\n",
    "model = MLPModel(input_size, hidden_sizes, output_size)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler=lr_scheduler.ReduceLROnPlateau(optimizer,mode='max',patience=10,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModel(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=5000, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1000, out_features=500, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=500, out_features=300, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.3, inplace=False)\n",
      "    (11): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.3128540723431479\n",
      "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
      "Epoch [2/100], Loss: 0.22528998931057942\n",
      "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
      "Epoch [3/100], Loss: 0.1909135689222862\n",
      "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
      "Epoch [4/100], Loss: 0.11709958847544014\n",
      "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
      "Epoch [5/100], Loss: 0.05156686990406838\n",
      "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
      "Epoch [6/100], Loss: 0.018468734439156722\n",
      "scheduler.num_bad_epochs: 2 scheduler.patience: 10\n",
      "Epoch [7/100], Loss: 0.0069873128035154\n",
      "scheduler.num_bad_epochs: 3 scheduler.patience: 10\n",
      "Epoch [8/100], Loss: 0.005330595432279406\n",
      "scheduler.num_bad_epochs: 4 scheduler.patience: 10\n",
      "Epoch [9/100], Loss: 0.004910171227460857\n",
      "scheduler.num_bad_epochs: 5 scheduler.patience: 10\n",
      "Epoch [10/100], Loss: 0.004034481215650174\n",
      "scheduler.num_bad_epochs: 6 scheduler.patience: 10\n",
      "Epoch [11/100], Loss: 0.0034456651164779953\n",
      "scheduler.num_bad_epochs: 7 scheduler.patience: 10\n",
      "Epoch [12/100], Loss: 0.0037927205362788827\n",
      "scheduler.num_bad_epochs: 8 scheduler.patience: 10\n",
      "Epoch [13/100], Loss: 0.003320519939981589\n",
      "scheduler.num_bad_epochs: 9 scheduler.patience: 10\n",
      "Epoch [14/100], Loss: 0.002432529553527206\n",
      "scheduler.num_bad_epochs: 10 scheduler.patience: 10\n",
      "Epoch [15/100], Loss: 0.0023420314117077166\n",
      "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
      "Epoch [16/100], Loss: 0.0009664161735096387\n",
      "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
      "Epoch [17/100], Loss: 8.738107303014294e-05\n",
      "scheduler.num_bad_epochs: 2 scheduler.patience: 10\n",
      "Epoch [18/100], Loss: 3.227909905669395e-05\n",
      "scheduler.num_bad_epochs: 3 scheduler.patience: 10\n",
      "Epoch [19/100], Loss: 8.965891512321966e-06\n",
      "scheduler.num_bad_epochs: 4 scheduler.patience: 10\n",
      "Epoch [20/100], Loss: 2.7708564998099887e-06\n",
      "scheduler.num_bad_epochs: 5 scheduler.patience: 10\n",
      "Epoch [21/100], Loss: 7.378650681703668e-07\n",
      "scheduler.num_bad_epochs: 6 scheduler.patience: 10\n",
      "Epoch [22/100], Loss: 2.5616747930840725e-07\n",
      "scheduler.num_bad_epochs: 7 scheduler.patience: 10\n",
      "Epoch [23/100], Loss: 1.5623281549206445e-07\n",
      "scheduler.num_bad_epochs: 8 scheduler.patience: 10\n",
      "Epoch [24/100], Loss: 1.3540602132473566e-07\n",
      "scheduler.num_bad_epochs: 9 scheduler.patience: 10\n",
      "Epoch [25/100], Loss: 7.131032108828626e-08\n",
      "scheduler.num_bad_epochs: 10 scheduler.patience: 10\n",
      "Epoch [26/100], Loss: 1.5452409246917284e-08\n",
      "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
      "Epoch [27/100], Loss: 7.635104551375583e-08\n",
      "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
      "Epoch [28/100], Loss: 1.6640627374081374e-08\n",
      "scheduler.num_bad_epochs: 2 scheduler.patience: 10\n",
      "Epoch [29/100], Loss: 1.4592037803393267e-08\n",
      "scheduler.num_bad_epochs: 3 scheduler.patience: 10\n",
      "Epoch [30/100], Loss: 5.648747997927514e-08\n",
      "scheduler.num_bad_epochs: 4 scheduler.patience: 10\n",
      "Epoch [31/100], Loss: 1.4673456571437353e-08\n",
      "scheduler.num_bad_epochs: 5 scheduler.patience: 10\n",
      "Epoch [32/100], Loss: 1.6213457876449198e-08\n",
      "scheduler.num_bad_epochs: 6 scheduler.patience: 10\n",
      "Epoch [33/100], Loss: 1.0170230683003679e-08\n",
      "scheduler.num_bad_epochs: 7 scheduler.patience: 10\n",
      "Epoch [34/100], Loss: 2.3280839548426924e-08\n",
      "scheduler.num_bad_epochs: 8 scheduler.patience: 10\n",
      "Epoch [35/100], Loss: 1.4533786609071759e-08\n",
      "scheduler.num_bad_epochs: 9 scheduler.patience: 10\n",
      "Epoch [36/100], Loss: 1.833833453791722e-08\n",
      "scheduler.num_bad_epochs: 10 scheduler.patience: 10\n",
      "Epoch [37/100], Loss: 2.5247948025351172e-08\n",
      "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
      "Epoch [38/100], Loss: 2.2520913464967618e-08\n",
      "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
      "Epoch [39/100], Loss: 7.704582493451894e-09\n",
      "scheduler.num_bad_epochs: 2 scheduler.patience: 10\n",
      "Epoch [40/100], Loss: 1.8032056487656803e-08\n",
      "scheduler.num_bad_epochs: 3 scheduler.patience: 10\n",
      "Epoch [41/100], Loss: 1.0117477847910522e-08\n",
      "scheduler.num_bad_epochs: 4 scheduler.patience: 10\n",
      "Epoch [42/100], Loss: 8.9419472941262e-09\n",
      "scheduler.num_bad_epochs: 5 scheduler.patience: 10\n",
      "Epoch [43/100], Loss: 6.2882258665660394e-09\n",
      "scheduler.num_bad_epochs: 6 scheduler.patience: 10\n",
      "Epoch [44/100], Loss: 5.900201837603209e-08\n",
      "scheduler.num_bad_epochs: 7 scheduler.patience: 10\n",
      "Epoch [45/100], Loss: 9.361913511204757e-08\n",
      "scheduler.num_bad_epochs: 8 scheduler.patience: 10\n",
      "Epoch [46/100], Loss: 2.547983146447119e-08\n",
      "scheduler.num_bad_epochs: 9 scheduler.patience: 10\n",
      "Epoch [47/100], Loss: 4.609840294503396e-09\n",
      "scheduler.num_bad_epochs: 10 scheduler.patience: 10\n",
      "Epoch [48/100], Loss: 1.0879286085399402e-07\n",
      "scheduler.num_bad_epochs: 0 scheduler.patience: 10\n",
      "Epoch [49/100], Loss: 5.053987733496491e-09\n",
      "scheduler.num_bad_epochs: 1 scheduler.patience: 10\n",
      "Epoch [50/100], Loss: 2.7947074844416174e-08\n",
      "scheduler.num_bad_epochs: 2 scheduler.patience: 10\n",
      "Epoch [51/100], Loss: 5.652923906714941e-09\n",
      "scheduler.num_bad_epochs: 3 scheduler.patience: 10\n",
      "Epoch [52/100], Loss: 1.73977044653923e-08\n",
      "scheduler.num_bad_epochs: 4 scheduler.patience: 10\n",
      "Epoch [53/100], Loss: 9.169070395565204e-09\n",
      "scheduler.num_bad_epochs: 5 scheduler.patience: 10\n",
      "Epoch [54/100], Loss: 1.7601502717426975e-08\n",
      "scheduler.num_bad_epochs: 6 scheduler.patience: 10\n",
      "Epoch [55/100], Loss: 7.00967889225542e-09\n",
      "scheduler.num_bad_epochs: 7 scheduler.patience: 10\n",
      "Epoch [56/100], Loss: 1.5852339055387387e-07\n",
      "scheduler.num_bad_epochs: 8 scheduler.patience: 10\n",
      "Epoch [57/100], Loss: 1.0117874793588285e-08\n",
      "scheduler.num_bad_epochs: 9 scheduler.patience: 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets\u001b[38;5;241m.\u001b[39mfloat())  \u001b[38;5;66;03m# float형으로 변환\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 18\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     22\u001b[0m avg_loss_train \u001b[38;5;241m=\u001b[39m epoch_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[1;32mc:\\Users\\desktop\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\optim\\optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m             )\n\u001b[1;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\desktop\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\optim\\optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\desktop\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\optim\\adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    217\u001b[0m         group,\n\u001b[0;32m    218\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    223\u001b[0m         state_steps,\n\u001b[0;32m    224\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\desktop\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\optim\\optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\desktop\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\optim\\adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\desktop\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\optim\\adam.py:431\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    429\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 431\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    433\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 7. 모델 학습\n",
    "epochs = 100\n",
    "patience = 10  # 성능 향상이 없을 때 10번의 에포크 후 학습을 중단\n",
    "\n",
    "best_loss = float('inf')  # 초기값을 매우 큰 값으로 설정\n",
    "trigger_times = 0  # 개선되지 않은 에포크 수\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_score=0\n",
    "    for features, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features).view(-1)\n",
    "        loss = criterion(outputs, targets.float())  # float형으로 변환\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss_train = epoch_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss_train}')\n",
    "\n",
    "    #최적화 스케줄러 인스턴스 업데이트\n",
    "    scheduler.step(loss)\n",
    "    print(f'scheduler.num_bad_epochs: {scheduler.num_bad_epochs}',end=' ')\n",
    "    print(f'scheduler.patience: {scheduler.patience}')\n",
    "\n",
    "#모델 평가\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, targets in test_loader:\n",
    "        outputs = model(features).view(-1)\n",
    "        predicted = torch.round(torch.sigmoid(outputs))  # 시그모이드 함수로 확률 변환\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(targets.cpu().numpy())\n",
    "\n",
    "# 성능 지표 계산\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#학습 결과 확인(학습과 검증의 Loss, 성능지표 변화 확인) w. 시각화\n",
    "\n",
    "th=len(score_history[1])\n",
    "fg,axes=plt.subplots(1,2,figsize=(10,5),sharey=True)\n",
    "axes[0].plot(range(1,th+1),loss_history[0][:th],label='Train')\n",
    "axes[0].plot(range(1,th+1),loss_history[1][:th],label='Val')\n",
    "axes[0].set_ylim([0.5,0.8])\n",
    "axes[0].grid()\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(range(1,th+1),score_history[0][:th],label='Train')\n",
    "axes[1].plot(range(1,th+1),score_history[1][:th],label='Val')\n",
    "axes[1].grid()\n",
    "\n",
    "axes[1].legend\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
