{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[사용자 정의 모델 클래스]\n",
    "- 부모클래스: nn.Module\n",
    "- 필수 오버라이딩:\n",
    "    - _ _init_ _(): 모델 층 구성(설계)\n",
    "    - forward(): 순방향 학습 진행 코드 구현\n",
    "- 동적 모델\n",
    "    - container 모듈 중 nn.ModuleList() 사용해서 동적으로 layer 추가\n",
    "        - forward 기능 제공 X\n",
    "        - layer 인스턴스 요소 사이에 연관성 X, 인덱싱으로 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모듈 로딩\n",
    "import torch                                #텐서 관련 모듈\n",
    "import torch.nn as nn                       #인공신경망 관련 모듈\n",
    "import torch.nn.functional as F             #인공신경망 관렴 함수 모듈(손실함수, 활성화함수 등)\n",
    "import torch.optim as optim                 #최적화 관련 모듈(가중치, 절편 빠르게 찾아주는 알고리즘)\n",
    "from torchinfo import summary               #모델 구조 및 정보 관련 모듈\n",
    "from torchmetrics.regression import *       #회귀 성능 지표 관련 모듈\n",
    "from torchmetrics.classification import *   #분류 성능 지표 관련 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#랜덤 고정\n",
    "torch.manual_seed(1)\n",
    "\n",
    "#저장 및 실행 위치 설정\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[모델 설계-동적 모델]\n",
    "- 목표: 은닉층의 개수가 동적인 모델\n",
    "- 조건\n",
    "    - 입력층과 출력층 개수 동적 => 입력층의 입력값, 출력층의 출력값 필요\n",
    "    - 은닉층의 개수 동적 + 퍼셉트론의 개수 고정 => 은닉층의 개수, 퍼셉트론 수 필요 \n",
    "- - -\n",
    "- 모델 이름: dynamicModel\n",
    "- 부모 클래스: nn.Module\n",
    "- 매개 변수: in_in, out_out, h_ins=[], h_outs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dynamicModel(nn.Module):\n",
    "    \n",
    "    #모델 구조 설계 함수(생성자 메서드)\n",
    "    def __init__(self,in_in,in_out,out_in,out_out,h_ins=[],h_outs=[]):\n",
    "\n",
    "        #부모 클래스 생성\n",
    "        super().__init__()\n",
    "\n",
    "        #설계\n",
    "        self.in_layer=nn.Linear(in_in,h_ins[0] if len(h_ins) else in_out)\n",
    "\n",
    "        self.h_layers=nn.ModuleList()\n",
    "        for idx in range(len(h_ins)):\n",
    "            self.h_layers.append(nn.Linear(h_ins[idx],h_outs[idx]))\n",
    "        \n",
    "        self.out_layer=nn.Linear(h_outs[-1] if len(h_outs) else out_in,out_out)      \n",
    "\n",
    "    #학습 진행 콜백 메서드\n",
    "    def forward(self,x):\n",
    "\n",
    "        #입력층\n",
    "        y=self.in_layer(x)          # y = x1·w1 + x2·w2 + x3·w3 + b\n",
    "        y=F.relu(y)                 # 0 <= y\n",
    "        # y=F.relu(self.in_layer(x))\n",
    "\n",
    "        #은닉층\n",
    "        for linear in self.h_layers:\n",
    "            y=linear(y)\n",
    "            y=F.relu(y)\n",
    "\n",
    "        #출력층\n",
    "        return self.out_layer(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dynamicModel(\n",
       "  (in_layer): Linear(in_features=3, out_features=30, bias=True)\n",
       "  (h_layers): ModuleList(\n",
       "    (0): Linear(in_features=30, out_features=50, bias=True)\n",
       "    (1): Linear(in_features=50, out_features=70, bias=True)\n",
       "    (2): Linear(in_features=70, out_features=30, bias=True)\n",
       "  )\n",
       "  (out_layer): Linear(in_features=30, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 구조 확인\n",
    "h_ins_=[30,50,70]\n",
    "h_outs_=[50,70,30]\n",
    "\n",
    "# h_ins=range(10,101,20)\n",
    "# h_outs=range(30,111,20)\n",
    "\n",
    "# h_inout=[10,30,50,70,90,110]\n",
    "# for idx in range(h_inout)-1:\n",
    "#     nn.Linear(h_inout[idx],h_inout[idx+1])\n",
    "\n",
    "m1=dynamicModel(3,5,5,2,h_ins=h_ins_,h_outs=h_outs_)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_layer.weight torch.Size([5, 3])\n",
      "in_layer.bias torch.Size([5])\n",
      "out_layer.weight torch.Size([2, 5])\n",
      "out_layer.bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "#모델 파라미터 확인\n",
    "for name,param in m1.named_parameters():\n",
    "    print(name,param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- [학습 진행] -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#임의의 데이터 생성\n",
    "dataTS=torch.FloatTensor([[1,3,5],[2,4,6],[3,5,7],[4,6,8]])     #2D (4,3)\n",
    "targetTS=torch.FloatTensor([[7,9],[8,10],[9,11],[10,12]])       #2D (4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1237, 0.0215],\n",
      "        [0.1237, 0.0215],\n",
      "        [0.1237, 0.0215],\n",
      "        [0.1237, 0.0215]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "#모델 학습\n",
    "pre_y=m1(dataTS)\n",
    "print(pre_y,pre_y.shape,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
