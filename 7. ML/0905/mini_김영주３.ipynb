{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zC3a9WyIbUd"
      },
      "source": [
        "데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RIfFwXyrzoTb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "HtsP9QOlzoTc",
        "outputId": "47dc3348-dc02-4b7c-de30-36df46cd57b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Platform</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>NA_Sales</th>\n",
              "      <th>EU_Sales</th>\n",
              "      <th>JP_Sales</th>\n",
              "      <th>Global_Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wii</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>41.49</td>\n",
              "      <td>29.02</td>\n",
              "      <td>3.77</td>\n",
              "      <td>82.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NES</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>29.08</td>\n",
              "      <td>3.58</td>\n",
              "      <td>6.81</td>\n",
              "      <td>40.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wii</td>\n",
              "      <td>Racing</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>15.85</td>\n",
              "      <td>12.88</td>\n",
              "      <td>3.79</td>\n",
              "      <td>35.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wii</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>15.75</td>\n",
              "      <td>11.01</td>\n",
              "      <td>3.28</td>\n",
              "      <td>33.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GB</td>\n",
              "      <td>Role-Playing</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>11.27</td>\n",
              "      <td>8.89</td>\n",
              "      <td>10.22</td>\n",
              "      <td>31.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16593</th>\n",
              "      <td>GBA</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Kemco</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16594</th>\n",
              "      <td>GC</td>\n",
              "      <td>Shooter</td>\n",
              "      <td>Infogrames</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16595</th>\n",
              "      <td>PS2</td>\n",
              "      <td>Racing</td>\n",
              "      <td>Activision</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16596</th>\n",
              "      <td>DS</td>\n",
              "      <td>Puzzle</td>\n",
              "      <td>7G//AMES</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16597</th>\n",
              "      <td>GBA</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Wanadoo</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16598 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Platform         Genre   Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
              "0          Wii        Sports    Nintendo     41.49     29.02      3.77   \n",
              "1          NES      Platform    Nintendo     29.08      3.58      6.81   \n",
              "2          Wii        Racing    Nintendo     15.85     12.88      3.79   \n",
              "3          Wii        Sports    Nintendo     15.75     11.01      3.28   \n",
              "4           GB  Role-Playing    Nintendo     11.27      8.89     10.22   \n",
              "...        ...           ...         ...       ...       ...       ...   \n",
              "16593      GBA      Platform       Kemco      0.01      0.00      0.00   \n",
              "16594       GC       Shooter  Infogrames      0.01      0.00      0.00   \n",
              "16595      PS2        Racing  Activision      0.00      0.00      0.00   \n",
              "16596       DS        Puzzle    7G//AMES      0.00      0.01      0.00   \n",
              "16597      GBA      Platform     Wanadoo      0.01      0.00      0.00   \n",
              "\n",
              "       Global_Sales  \n",
              "0             82.74  \n",
              "1             40.24  \n",
              "2             35.82  \n",
              "3             33.00  \n",
              "4             31.37  \n",
              "...             ...  \n",
              "16593          0.01  \n",
              "16594          0.01  \n",
              "16595          0.01  \n",
              "16596          0.01  \n",
              "16597          0.01  \n",
              "\n",
              "[16598 rows x 7 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "game=pd.read_csv('../data/vgsales.csv', usecols=[2,4,5,6,7,8,10])\n",
        "game"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "29p1Xxdi8UO_",
        "outputId": "b6eca2bc-4df3-4c47-e6dd-a065644ed91f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Platform         0\n",
              "Genre            0\n",
              "Publisher       58\n",
              "NA_Sales         0\n",
              "EU_Sales         0\n",
              "JP_Sales         0\n",
              "Global_Sales     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "game.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iz7qRWu1zoTc",
        "outputId": "ed2c2307-f1e8-4e5c-c96e-aae257e952b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Platform</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>NA_Sales</th>\n",
              "      <th>EU_Sales</th>\n",
              "      <th>JP_Sales</th>\n",
              "      <th>Global_Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wii</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>41.49</td>\n",
              "      <td>29.02</td>\n",
              "      <td>3.77</td>\n",
              "      <td>82.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NES</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>29.08</td>\n",
              "      <td>3.58</td>\n",
              "      <td>6.81</td>\n",
              "      <td>40.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wii</td>\n",
              "      <td>Racing</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>15.85</td>\n",
              "      <td>12.88</td>\n",
              "      <td>3.79</td>\n",
              "      <td>35.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wii</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>15.75</td>\n",
              "      <td>11.01</td>\n",
              "      <td>3.28</td>\n",
              "      <td>33.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GB</td>\n",
              "      <td>Role-Playing</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>11.27</td>\n",
              "      <td>8.89</td>\n",
              "      <td>10.22</td>\n",
              "      <td>31.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16593</th>\n",
              "      <td>GBA</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Kemco</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16594</th>\n",
              "      <td>GC</td>\n",
              "      <td>Shooter</td>\n",
              "      <td>Infogrames</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16595</th>\n",
              "      <td>PS2</td>\n",
              "      <td>Racing</td>\n",
              "      <td>Activision</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16596</th>\n",
              "      <td>DS</td>\n",
              "      <td>Puzzle</td>\n",
              "      <td>7G//AMES</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16597</th>\n",
              "      <td>GBA</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Wanadoo</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16540 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Platform         Genre   Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
              "0          Wii        Sports    Nintendo     41.49     29.02      3.77   \n",
              "1          NES      Platform    Nintendo     29.08      3.58      6.81   \n",
              "2          Wii        Racing    Nintendo     15.85     12.88      3.79   \n",
              "3          Wii        Sports    Nintendo     15.75     11.01      3.28   \n",
              "4           GB  Role-Playing    Nintendo     11.27      8.89     10.22   \n",
              "...        ...           ...         ...       ...       ...       ...   \n",
              "16593      GBA      Platform       Kemco      0.01      0.00      0.00   \n",
              "16594       GC       Shooter  Infogrames      0.01      0.00      0.00   \n",
              "16595      PS2        Racing  Activision      0.00      0.00      0.00   \n",
              "16596       DS        Puzzle    7G//AMES      0.00      0.01      0.00   \n",
              "16597      GBA      Platform     Wanadoo      0.01      0.00      0.00   \n",
              "\n",
              "       Global_Sales  \n",
              "0             82.74  \n",
              "1             40.24  \n",
              "2             35.82  \n",
              "3             33.00  \n",
              "4             31.37  \n",
              "...             ...  \n",
              "16593          0.01  \n",
              "16594          0.01  \n",
              "16595          0.01  \n",
              "16596          0.01  \n",
              "16597          0.01  \n",
              "\n",
              "[16540 rows x 7 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "game=game.dropna()\n",
        "game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRSMqguW7GwU"
      },
      "source": [
        "platforms_to_keep = ['X360', 'XOne', 'XB',  # Xbox 계열\n",
        "\n",
        "                     'PS2', 'PS3', 'PS4', 'PS', 'PSP', 'PSV',  # PlayStation 계열\n",
        "                     \n",
        "                     'Wii', 'WiiU', 'GB', 'GBA', 'DS', '3DS', 'SNES', 'NES', 'N64', 'GC']   #Nintendo 계열"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "3hgWnCK_5o9c",
        "outputId": "3202ced2-f7fc-4e44-8aea-e81ed07a9f08"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\desktop\\AppData\\Local\\Temp\\ipykernel_18304\\970802486.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  game['Platform'].replace(i, 'Nintendo', inplace=True)\n",
            "C:\\Users\\desktop\\AppData\\Local\\Temp\\ipykernel_18304\\970802486.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  game['Platform'].replace(i, 'Xbox', inplace=True)\n",
            "C:\\Users\\desktop\\AppData\\Local\\Temp\\ipykernel_18304\\970802486.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  game['Platform'].replace(i, 'PlayStation', inplace=True)\n",
            "C:\\Users\\desktop\\AppData\\Local\\Temp\\ipykernel_18304\\970802486.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  game['Platform'].replace(i, 'Other', inplace=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Platform</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>NA_Sales</th>\n",
              "      <th>EU_Sales</th>\n",
              "      <th>JP_Sales</th>\n",
              "      <th>Global_Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>41.49</td>\n",
              "      <td>29.02</td>\n",
              "      <td>3.77</td>\n",
              "      <td>82.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>29.08</td>\n",
              "      <td>3.58</td>\n",
              "      <td>6.81</td>\n",
              "      <td>40.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Racing</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>15.85</td>\n",
              "      <td>12.88</td>\n",
              "      <td>3.79</td>\n",
              "      <td>35.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>15.75</td>\n",
              "      <td>11.01</td>\n",
              "      <td>3.28</td>\n",
              "      <td>33.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Role-Playing</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>11.27</td>\n",
              "      <td>8.89</td>\n",
              "      <td>10.22</td>\n",
              "      <td>31.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16593</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Kemco</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16594</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Shooter</td>\n",
              "      <td>Infogrames</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16595</th>\n",
              "      <td>PlayStation</td>\n",
              "      <td>Racing</td>\n",
              "      <td>Activision</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16596</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Puzzle</td>\n",
              "      <td>7G//AMES</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16597</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Wanadoo</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16540 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Platform         Genre   Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
              "0         Nintendo        Sports    Nintendo     41.49     29.02      3.77   \n",
              "1         Nintendo      Platform    Nintendo     29.08      3.58      6.81   \n",
              "2         Nintendo        Racing    Nintendo     15.85     12.88      3.79   \n",
              "3         Nintendo        Sports    Nintendo     15.75     11.01      3.28   \n",
              "4         Nintendo  Role-Playing    Nintendo     11.27      8.89     10.22   \n",
              "...            ...           ...         ...       ...       ...       ...   \n",
              "16593     Nintendo      Platform       Kemco      0.01      0.00      0.00   \n",
              "16594     Nintendo       Shooter  Infogrames      0.01      0.00      0.00   \n",
              "16595  PlayStation        Racing  Activision      0.00      0.00      0.00   \n",
              "16596     Nintendo        Puzzle    7G//AMES      0.00      0.01      0.00   \n",
              "16597     Nintendo      Platform     Wanadoo      0.01      0.00      0.00   \n",
              "\n",
              "       Global_Sales  \n",
              "0             82.74  \n",
              "1             40.24  \n",
              "2             35.82  \n",
              "3             33.00  \n",
              "4             31.37  \n",
              "...             ...  \n",
              "16593          0.01  \n",
              "16594          0.01  \n",
              "16595          0.01  \n",
              "16596          0.01  \n",
              "16597          0.01  \n",
              "\n",
              "[16540 rows x 7 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i in game['Platform']:\n",
        "    if i in ('X360', 'XOne', 'XB','Xbox'):\n",
        "      game['Platform'].replace(i, 'Xbox', inplace=True)\n",
        "    elif i in ('PS2', 'PS3', 'PS4', 'PS', 'PSP', 'PSV','PlayStation'):\n",
        "      game['Platform'].replace(i, 'PlayStation', inplace=True)\n",
        "    elif i in ('Wii', 'WiiU', 'GB', 'GBA', 'DS', '3DS', 'SNES', 'NES', 'N64', 'GC','Nintendo'):\n",
        "      game['Platform'].replace(i, 'Nintendo', inplace=True)\n",
        "    else:\n",
        "      game['Platform'].replace(i, 'Other', inplace=True)\n",
        "\n",
        "game"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "5n73sYpl78nt",
        "outputId": "28e7bf78-9af7-46e6-eeb1-66c97602e821"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Platform\n",
              "PlayStation    6636\n",
              "Nintendo       6236\n",
              "Xbox           2298\n",
              "Other          1370\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "game.value_counts('Platform')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wCqMlVgnzoTd",
        "outputId": "53a3adbf-eb20-49b7-f44b-210752e2f873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Platform ['Nintendo' 'Xbox' 'PlayStation' 'Other']\n",
            "Genre ['Sports' 'Platform' 'Racing' 'Role-Playing' 'Puzzle' 'Misc' 'Shooter'\n",
            " 'Simulation' 'Action' 'Fighting' 'Adventure' 'Strategy']\n",
            "Publisher ['Nintendo' 'Microsoft Game Studios' 'Take-Two Interactive'\n",
            " 'Sony Computer Entertainment' 'Activision' 'Ubisoft' 'Bethesda Softworks'\n",
            " 'Electronic Arts' 'Sega' 'SquareSoft' 'Atari' '505 Games' 'Capcom'\n",
            " 'GT Interactive' 'Konami Digital Entertainment'\n",
            " 'Sony Computer Entertainment Europe' 'Square Enix' 'LucasArts'\n",
            " 'Virgin Interactive' 'Warner Bros. Interactive Entertainment'\n",
            " 'Universal Interactive' 'Eidos Interactive' 'RedOctane' 'Vivendi Games'\n",
            " 'Enix Corporation' 'Namco Bandai Games' 'Palcom' 'Hasbro Interactive'\n",
            " 'THQ' 'Fox Interactive' 'Acclaim Entertainment' 'MTV Games'\n",
            " 'Disney Interactive Studios' 'Majesco Entertainment' 'Codemasters'\n",
            " 'Red Orb' 'Level 5' 'Arena Entertainment' 'Midway Games' 'JVC'\n",
            " 'Deep Silver' '989 Studios' 'NCSoft' 'UEP Systems' 'Parker Bros.' 'Maxis'\n",
            " 'Imagic' 'Tecmo Koei' 'Valve Software' 'ASCII Entertainment' 'Mindscape'\n",
            " 'Infogrames' 'Unknown' 'Square' 'Valve' 'Activision Value' 'Banpresto'\n",
            " 'D3Publisher' 'Oxygen Interactive' 'Red Storm Entertainment'\n",
            " 'Video System' 'Hello Games' 'Global Star' 'Gotham Games'\n",
            " 'Westwood Studios' 'GungHo' 'Crave Entertainment' 'Hudson Soft' 'Coleco'\n",
            " 'Rising Star Games' 'Atlus' 'TDK Mediactive' 'ASC Games' 'Zoo Games'\n",
            " 'Accolade' 'Sony Online Entertainment' '3DO' 'RTL' 'Natsume'\n",
            " 'Focus Home Interactive' 'Alchemist' 'Black Label Games'\n",
            " 'SouthPeak Games' 'Mastertronic' 'Ocean' 'Zoo Digital Publishing'\n",
            " 'Psygnosis' 'City Interactive' 'Empire Interactive' 'Success' 'Compile'\n",
            " 'Russel' 'Taito' 'Agetec' 'GSP' 'Microprose' 'Play It'\n",
            " 'Slightly Mad Studios' 'Tomy Corporation' 'Sammy Corporation'\n",
            " 'Koch Media' 'Game Factory' 'Titus' 'Marvelous Entertainment' 'Genki'\n",
            " 'Mojang' 'Pinnacle' 'CTO SpA' 'TalonSoft' 'Crystal Dynamics' 'SCi'\n",
            " 'Quelle' 'mixi, Inc' 'Rage Software' 'Ubisoft Annecy' 'Scholastic Inc.'\n",
            " 'Interplay' 'Mystique' 'ChunSoft' 'Square EA'\n",
            " '20th Century Fox Video Games' 'Avanquest Software'\n",
            " 'Hudson Entertainment' 'Nordic Games' 'Men-A-Vision' 'Nobilis'\n",
            " 'Big Ben Interactive' 'Touchstone' 'Spike' 'Jester Interactive'\n",
            " 'Nippon Ichi Software' 'LEGO Media' 'Quest' 'Illusion Softworks'\n",
            " 'Tigervision' 'Funbox Media' 'Rocket Company' 'Metro 3D'\n",
            " 'Mattel Interactive' 'IE Institute' 'Rondomedia'\n",
            " 'Sony Computer Entertainment America' 'Universal Gamex' 'Ghostlight'\n",
            " 'Wizard Video Games' 'BMG Interactive Entertainment' 'PQube'\n",
            " 'Trion Worlds' 'Laguna' 'Ignition Entertainment' 'Takara'\n",
            " 'Kadokawa Shoten' 'Destineer' 'Enterbrain' 'Xseed Games' 'Imagineer'\n",
            " 'System 3 Arcade Software' 'CPG Products' 'Aruze Corp' 'Gamebridge'\n",
            " 'Midas Interactive Entertainment' 'Jaleco' 'Answer Software' 'XS Games'\n",
            " 'Activision Blizzard' 'Pack In Soft' 'Rebellion' 'Xplosiv' 'Ultravision'\n",
            " 'GameMill Entertainment' 'Wanadoo' 'NovaLogic' 'Telltale Games' 'Epoch'\n",
            " 'BAM! Entertainment' 'Knowledge Adventure' 'Mastiff' 'Tetris Online'\n",
            " 'Harmonix Music Systems' 'ESP' 'TYO' 'Telegames' 'Mud Duck Productions'\n",
            " 'Screenlife' 'Pioneer LDC' 'Magical Company' 'Mentor Interactive' 'Kemco'\n",
            " 'Human Entertainment' 'Avanquest' 'Data Age' 'Electronic Arts Victor'\n",
            " 'Black Bean Games' 'Jack of All Games' '989 Sports' 'Takara Tomy'\n",
            " 'Media Rings' 'Elf' 'Kalypso Media' 'Starfish' 'Zushi Games' 'Jorudan'\n",
            " 'Destination Software, Inc' 'New' 'Brash Entertainment'\n",
            " 'ITT Family Games' 'PopCap Games' 'Home Entertainment Suppliers'\n",
            " 'Ackkstudios' 'Starpath Corp.' 'P2 Games' 'BPS' 'Gathering of Developers'\n",
            " 'NewKidCo' 'Storm City Games' 'CokeM Interactive' 'CBS Electronics'\n",
            " 'Magix' 'Marvelous Interactive' 'Nihon Falcom Corporation'\n",
            " 'Wargaming.net' 'Angel Studios' 'Arc System Works' 'Playmates'\n",
            " 'SNK Playmore' 'Hamster Corporation' 'From Software' 'Nippon Columbia'\n",
            " 'Nichibutsu' 'Little Orbit' 'Conspiracy Entertainment'\n",
            " 'DTP Entertainment' 'Hect' 'Mumbo Jumbo' 'Pacific Century Cyber Works'\n",
            " 'Indie Games' 'Liquid Games' 'NEC' 'Axela' 'ArtDink' 'Sunsoft' 'Gust'\n",
            " 'SNK' 'NEC Interchannel' 'FuRyu' 'Xing Entertainment' 'ValuSoft'\n",
            " 'Victor Interactive' 'Detn8 Games' 'American Softworks' 'Nordcurrent'\n",
            " 'Bomb' 'Falcom Corporation' 'AQ Interactive' 'CCP' 'Milestone S.r.l.'\n",
            " 'Sears' 'JoWood Productions' 'Seta Corporation' 'On Demand' 'NCS' 'Aspyr'\n",
            " 'Gremlin Interactive Ltd' 'Agatsuma Entertainment' 'Compile Heart'\n",
            " 'Culture Brain' 'Mad Catz' 'Shogakukan' 'Merscom LLC'\n",
            " 'Rebellion Developments' 'Nippon Telenet' 'TDK Core' 'bitComposer Games'\n",
            " 'Foreign Media Games' 'Astragon' 'SSI' 'Kadokawa Games' 'Idea Factory'\n",
            " 'Performance Designed Products' 'Asylum Entertainment' 'Core Design Ltd.'\n",
            " 'PlayV' 'UFO Interactive' 'Idea Factory International'\n",
            " 'Playlogic Game Factory' 'Essential Games' 'Adeline Software' 'Funcom'\n",
            " 'Panther Software' 'Blast! Entertainment Ltd' 'Game Life' 'DSI Games'\n",
            " 'Avalon Interactive' 'Popcorn Arcade' 'Neko Entertainment'\n",
            " 'Vir2L Studios' 'Aques' 'Syscom' 'White Park Bay Software' 'System 3'\n",
            " 'Vatical Entertainment' 'Daedalic' 'EA Games' 'Media Factory' 'Vic Tokai'\n",
            " 'The Adventure Company' 'Game Arts' 'Broccoli' 'Acquire'\n",
            " 'General Entertainment' 'Excalibur Publishing' 'Imadio'\n",
            " 'Swing! Entertainment' 'Sony Music Entertainment' 'Aqua Plus'\n",
            " 'Paradox Interactive' 'Hip Interactive' 'DreamCatcher Interactive'\n",
            " 'Tripwire Interactive' 'Sting' 'Yacht Club Games' 'SCS Software'\n",
            " 'Bigben Interactive' 'Havas Interactive' 'Slitherine Software' 'Graffiti'\n",
            " 'Funsta' 'Telstar' 'U.S. Gold' 'DreamWorks Interactive'\n",
            " 'Data Design Interactive' 'MTO' 'DHM Interactive' 'FunSoft' 'SPS'\n",
            " 'Bohemia Interactive' 'Reef Entertainment' 'Tru Blu Entertainment' 'Moss'\n",
            " 'T&E Soft' 'O-Games' 'Aksys Games' 'NDA Productions' 'Data East'\n",
            " 'Time Warner Interactive' 'Gainax Network Systems' 'Daito'\n",
            " 'O3 Entertainment' 'Gameloft' 'Xicat Interactive'\n",
            " 'Simon & Schuster Interactive' 'Valcon Games' 'PopTop Software' 'TOHO'\n",
            " 'HMH Interactive' '5pb' 'Cave' 'CDV Software Entertainment' 'Microids'\n",
            " 'PM Studios' 'Paon' 'Micro Cabin' 'GameTek' 'Benesse' 'Type-Moon'\n",
            " 'Enjoy Gaming ltd.' 'Asmik Corp' 'Interplay Productions'\n",
            " 'Asmik Ace Entertainment' 'inXile Entertainment' 'Image Epoch'\n",
            " 'Phantom EFX' 'Evolved Games' 'responDESIGN' 'Culture Publishers'\n",
            " 'Griffin International' 'Hackberry' 'Hearty Robin' 'Nippon Amuse'\n",
            " 'Origin Systems' 'Seventh Chord' 'Mitsui' 'Milestone' 'Abylight'\n",
            " 'Flight-Plan' 'Glams' 'Locus' 'Warp' 'Daedalic Entertainment'\n",
            " 'Alternative Software' 'Myelin Media' 'Mercury Games'\n",
            " 'Irem Software Engineering' 'Sunrise Interactive' 'Elite'\n",
            " 'Evolution Games' 'Tivola' 'Global A Entertainment' 'Edia' 'Athena'\n",
            " 'Aria' 'Gamecock' 'Tommo' 'Altron' 'Happinet' 'iWin' 'Media Works'\n",
            " 'Fortyfive' 'Revolution Software' 'Imax' 'Crimson Cow' '10TACLE Studios'\n",
            " 'Groove Games' 'Pack-In-Video' 'Insomniac Games'\n",
            " 'Ascaron Entertainment GmbH' 'Asgard' 'Ecole' 'Yumedia' 'Phenomedia'\n",
            " 'HAL Laboratory' 'Grand Prix Games' 'DigiCube' 'Creative Core'\n",
            " 'Kaga Create' 'WayForward Technologies' 'LSP Games' 'ASCII Media Works'\n",
            " 'Coconuts Japan' 'Arika' 'Ertain' 'Marvel Entertainment' 'Prototype'\n",
            " 'TopWare Interactive' 'Phantagram' '1C Company' 'The Learning Company'\n",
            " 'TechnoSoft' 'Vap' 'Misawa' 'Tradewest' 'Team17 Software' 'Yeti' 'Pow'\n",
            " 'Navarre Corp' 'MediaQuest' 'Max Five' 'Comfort'\n",
            " 'Monte Christo Multimedia' 'Pony Canyon' 'Riverhillsoft' 'Summitsoft'\n",
            " 'Milestone S.r.l' 'Playmore' 'MLB.com' 'Kool Kizz' 'Flashpoint Games'\n",
            " '49Games' 'Legacy Interactive' 'Alawar Entertainment' 'CyberFront'\n",
            " 'Cloud Imperium Games Corporation' 'Societa' 'Virtual Play Games'\n",
            " 'Interchannel' 'Sonnet' 'Experience Inc.' 'Zenrin' 'Iceberg Interactive'\n",
            " 'Ivolgamus' '2D Boy' 'MC2 Entertainment' 'Kando Games' 'Just Flight'\n",
            " 'Office Create' 'Mamba Games' 'Fields' 'Princess Soft'\n",
            " 'Maximum Family Games' 'Berkeley' 'Fuji' 'Dusenberry Martin Racing'\n",
            " 'imageepoch Inc.' 'Big Fish Games' 'Her Interactive' 'Kamui' 'ASK'\n",
            " 'Headup Games' 'KSS' 'Cygames' 'KID' 'Quinrose' 'Sunflowers'\n",
            " 'dramatic create' 'TGL' 'Encore' 'Extreme Entertainment Group'\n",
            " 'Intergrow' 'G.Rev' 'Sweets' 'Kokopeli Digital Studios' 'Number None'\n",
            " 'Nexon' 'id Software' 'BushiRoad' 'Tryfirst' 'Strategy First' '7G//AMES'\n",
            " 'GN Software' \"Yuke's\" 'Easy Interactive' 'Licensed 4U'\n",
            " 'FuRyu Corporation' 'Lexicon Entertainment' 'Paon Corporation'\n",
            " 'Kids Station' 'GOA' 'Graphsim Entertainment' 'King Records'\n",
            " 'Introversion Software' 'Minato Station' 'Devolver Digital' 'Blue Byte'\n",
            " 'Gaga' 'Yamasa Entertainment' 'Plenty' 'Views' 'fonfun' 'NetRevo'\n",
            " 'Codemasters Online' 'Quintet' 'Phoenix Games' 'Dorart' 'Marvelous Games'\n",
            " 'Focus Multimedia' 'Imageworks' 'Karin Entertainment' 'Aerosoft'\n",
            " 'Technos Japan Corporation' 'Gakken' 'Mirai Shounen' 'Datam Polystar'\n",
            " 'Saurus' 'HuneX' 'Revolution (Japan)' 'Giza10' 'Visco' 'Alvion' 'Mycom'\n",
            " 'Giga' 'Warashi' 'System Soft' 'Sold Out' 'Lighthouse Interactive'\n",
            " 'Masque Publishing' 'RED Entertainment' 'Michaelsoft'\n",
            " 'Media Entertainment' 'New World Computing' 'Genterprise'\n",
            " 'Interworks Unlimited, Inc.' 'Boost On' 'Stainless Games'\n",
            " 'EON Digital Entertainment' 'Epic Games' 'Naxat Soft'\n",
            " 'Ascaron Entertainment' 'Piacci' 'Nitroplus' 'Paradox Development'\n",
            " 'Otomate' 'Ongakukan' 'Commseed' 'Inti Creates' 'Takuyo'\n",
            " 'Interchannel-Holon' 'Rain Games' 'UIG Entertainment']\n",
            "NA_Sales [4.149e+01 2.908e+01 1.585e+01 1.575e+01 1.127e+01 2.320e+01 1.138e+01\n",
            " 1.403e+01 1.459e+01 2.693e+01 9.070e+00 9.810e+00 9.000e+00 8.940e+00\n",
            " 9.090e+00 1.497e+01 7.010e+00 9.430e+00 1.278e+01 4.750e+00 6.420e+00\n",
            " 1.083e+01 9.540e+00 9.630e+00 8.410e+00 6.060e+00 5.570e+00 3.440e+00\n",
            " 6.850e+00 9.030e+00 5.890e+00 9.670e+00 5.170e+00 5.770e+00 4.990e+00\n",
            " 8.250e+00 8.520e+00 5.540e+00 6.990e+00 6.750e+00 5.980e+00 2.550e+00\n",
            " 4.740e+00 7.970e+00 3.800e+00 4.400e+00 6.910e+00 3.010e+00 6.160e+00\n",
            " 4.230e+00 6.760e+00 4.020e+00 4.890e+00 2.960e+00 4.760e+00 5.990e+00\n",
            " 4.340e+00 5.080e+00 6.050e+00 6.720e+00 7.030e+00 5.550e+00 3.660e+00\n",
            " 6.630e+00 4.090e+00 5.840e+00 3.880e+00 5.910e+00 4.360e+00 5.580e+00\n",
            " 2.010e+00 4.460e+00 5.030e+00 3.540e+00 1.110e+00 1.790e+00 6.820e+00\n",
            " 3.810e+00 2.910e+00 1.060e+00 9.800e-01 5.800e+00 2.580e+00 2.280e+00\n",
            " 2.820e+00 7.280e+00 2.900e+00 2.930e+00 2.800e+00 4.100e+00 3.780e+00\n",
            " 5.390e+00 3.240e+00 4.790e+00 3.830e+00 4.520e+00 3.510e+00 2.850e+00\n",
            " 3.270e+00 3.680e+00 4.410e+00 3.130e+00 2.470e+00 4.120e+00 4.140e+00\n",
            " 7.800e-01 2.710e+00 2.770e+00 3.230e+00 3.500e+00 4.150e+00 3.100e+00\n",
            " 8.400e-01 1.670e+00 2.790e+00 7.900e-01 3.250e+00 3.740e+00 2.640e+00\n",
            " 4.980e+00 2.570e+00 3.640e+00 3.700e+00 4.010e+00 7.000e-02 3.110e+00\n",
            " 3.920e+00 4.050e+00 2.450e+00 4.470e+00 2.630e+00 3.180e+00 2.410e+00\n",
            " 1.880e+00 6.600e-01 2.260e+00 2.490e+00 2.970e+00 2.540e+00 2.950e+00\n",
            " 3.280e+00 2.700e+00 2.990e+00 4.700e-01 3.140e+00 2.620e+00 3.210e+00\n",
            " 2.720e+00 2.070e+00 1.970e+00 1.740e+00 2.180e+00 3.020e+00 1.620e+00\n",
            " 1.920e+00 3.330e+00 1.220e+00 2.300e+00 4.260e+00 6.500e-01 2.430e+00\n",
            " 2.320e+00 1.080e+00 1.900e+00 2.100e+00 9.600e-01 1.640e+00 1.980e+00\n",
            " 3.590e+00 3.220e+00 1.960e+00 2.660e+00 1.700e+00 6.000e-01 3.400e+00\n",
            " 2.050e+00 3.420e+00 2.590e+00 3.360e+00 3.060e+00 3.490e+00 3.390e+00\n",
            " 1.850e+00 2.310e+00 3.980e+00 2.890e+00 0.000e+00 2.740e+00 2.560e+00\n",
            " 1.910e+00 5.700e-01 2.800e-01 2.360e+00 1.730e+00 3.050e+00 1.870e+00\n",
            " 1.940e+00 2.080e+00 2.290e+00 2.420e+00 2.600e+00 1.890e+00 1.780e+00\n",
            " 1.550e+00 3.190e+00 4.180e+00 4.210e+00 3.630e+00 2.000e-01 1.540e+00\n",
            " 2.670e+00 1.000e-01 2.190e+00 2.030e+00 3.030e+00 2.200e+00 9.200e-01\n",
            " 2.750e+00 4.000e+00 2.510e+00 2.110e+00 2.230e+00 1.410e+00 3.000e+00\n",
            " 1.460e+00 8.800e-01 1.300e+00 1.280e+00 2.250e+00 2.020e+00 3.380e+00\n",
            " 2.040e+00 3.790e+00 1.400e+00 4.030e+00 1.650e+00 7.100e-01 2.140e+00\n",
            " 1.420e+00 2.130e+00 2.650e+00 2.350e+00 1.200e-01 1.680e+00 1.120e+00\n",
            " 2.780e+00 1.380e+00 2.150e+00 1.180e+00 1.330e+00 6.700e-01 1.530e+00\n",
            " 1.150e+00 9.300e-01 2.120e+00 2.480e+00 1.600e-01 8.700e-01 2.210e+00\n",
            " 1.440e+00 1.490e+00 1.140e+00 2.400e+00 1.820e+00 1.370e+00 1.930e+00\n",
            " 5.800e-01 1.590e+00 2.530e+00 2.330e+00 5.000e-02 1.610e+00 2.380e+00\n",
            " 1.570e+00 1.560e+00 1.230e+00 1.660e+00 1.170e+00 2.840e+00 5.900e-01\n",
            " 2.090e+00 2.390e+00 1.340e+00 1.130e+00 8.600e-01 1.750e+00 4.600e-01\n",
            " 1.430e+00 1.630e+00 1.450e+00 1.470e+00 1.990e+00 1.500e+00 8.000e-01\n",
            " 1.360e+00 5.000e-01 2.500e-01 9.500e-01 1.270e+00 3.000e-02 1.720e+00\n",
            " 7.300e-01 1.760e+00 1.350e+00 1.480e+00 1.520e+00 1.860e+00 2.060e+00\n",
            " 6.800e-01 9.100e-01 1.690e+00 8.000e-02 1.290e+00 2.170e+00 2.500e+00\n",
            " 1.010e+00 1.580e+00 1.040e+00 2.220e+00 1.830e+00 6.100e-01 1.840e+00\n",
            " 9.900e-01 1.510e+00 9.000e-02 4.000e-01 2.520e+00 1.320e+00 2.000e-02\n",
            " 1.050e+00 2.900e-01 1.190e+00 8.900e-01 3.000e-01 1.200e+00 1.240e+00\n",
            " 1.250e+00 1.070e+00 1.020e+00 6.900e-01 1.950e+00 2.000e+00 7.600e-01\n",
            " 6.300e-01 9.000e-01 4.800e-01 6.400e-01 3.700e-01 1.310e+00 1.500e-01\n",
            " 1.210e+00 4.900e-01 1.300e-01 1.810e+00 1.260e+00 8.100e-01 7.700e-01\n",
            " 1.000e+00 1.160e+00 1.390e+00 8.500e-01 5.200e-01 5.100e-01 3.800e-01\n",
            " 6.200e-01 1.090e+00 1.710e+00 1.030e+00 3.400e-01 1.600e+00 5.400e-01\n",
            " 1.400e-01 1.000e-02 8.200e-01 8.300e-01 1.100e-01 9.400e-01 1.770e+00\n",
            " 7.000e-01 9.700e-01 7.500e-01 3.500e-01 7.200e-01 7.400e-01 1.800e-01\n",
            " 1.100e+00 5.600e-01 2.600e-01 2.100e-01 2.200e-01 5.300e-01 5.500e-01\n",
            " 2.300e-01 3.900e-01 3.200e-01 4.500e-01 4.100e-01 3.100e-01 2.400e-01\n",
            " 6.000e-02 4.300e-01 4.400e-01 1.900e-01 4.000e-02 1.700e-01 3.600e-01\n",
            " 3.300e-01 2.700e-01 4.200e-01]\n",
            "EU_Sales [2.902e+01 3.580e+00 1.288e+01 1.101e+01 8.890e+00 2.260e+00 9.230e+00\n",
            " 9.200e+00 7.060e+00 6.300e-01 1.100e+01 7.570e+00 6.180e+00 8.030e+00\n",
            " 8.590e+00 4.940e+00 9.270e+00 4.000e-01 3.750e+00 9.260e+00 4.520e+00\n",
            " 2.710e+00 3.440e+00 5.310e+00 5.490e+00 3.900e+00 3.280e+00 5.360e+00\n",
            " 5.090e+00 4.280e+00 5.040e+00 3.730e+00 4.050e+00 5.810e+00 5.880e+00\n",
            " 4.300e+00 3.630e+00 5.820e+00 4.510e+00 2.610e+00 4.440e+00 3.520e+00\n",
            " 3.910e+00 2.830e+00 2.770e+00 2.850e+00 1.000e-02 3.400e+00 3.370e+00\n",
            " 2.040e+00 3.100e+00 3.870e+00 2.990e+00 4.880e+00 3.690e+00 3.760e+00\n",
            " 2.150e+00 2.650e+00 3.110e+00 3.150e+00 2.630e+00 1.980e+00 1.940e+00\n",
            " 3.070e+00 2.360e+00 2.470e+00 2.890e+00 3.420e+00 2.380e+00 1.710e+00\n",
            " 2.320e+00 1.880e+00 2.860e+00 1.240e+00 6.060e+00 3.530e+00 1.530e+00\n",
            " 2.300e+00 1.860e+00 5.050e+00 6.420e+00 2.010e+00 2.070e+00 1.720e+00\n",
            " 1.780e+00 4.500e-01 2.420e+00 3.290e+00 3.300e+00 1.890e+00 2.170e+00\n",
            " 1.180e+00 1.350e+00 1.900e+00 2.130e+00 2.190e+00 2.090e+00 3.030e+00\n",
            " 2.930e+00 2.220e+00 1.750e+00 1.040e+00 1.770e+00 2.210e+00 4.320e+00\n",
            " 3.020e+00 2.750e+00 2.800e+00 2.350e+00 2.640e+00 1.920e+00 2.250e+00\n",
            " 2.780e+00 4.290e+00 1.840e+00 9.300e-01 2.560e+00 1.300e+00 1.580e+00\n",
            " 1.200e+00 1.560e+00 1.970e+00 1.260e+00 8.300e-01 6.210e+00 1.620e+00\n",
            " 1.740e+00 1.830e+00 2.280e+00 0.000e+00 2.050e+00 6.900e-01 1.630e+00\n",
            " 1.470e+00 1.950e+00 6.000e-01 1.650e+00 1.910e+00 5.700e-01 1.640e+00\n",
            " 1.110e+00 1.870e+00 2.290e+00 2.510e+00 9.600e-01 1.120e+00 7.700e-01\n",
            " 1.080e+00 7.900e-01 2.480e+00 2.460e+00 2.600e-01 7.500e-01 1.250e+00\n",
            " 9.800e-01 3.480e+00 7.400e-01 2.020e+00 2.230e+00 6.100e-01 1.690e+00\n",
            " 1.430e+00 1.160e+00 1.380e+00 1.060e+00 1.360e+00 1.030e+00 1.730e+00\n",
            " 1.540e+00 9.900e-01 1.680e+00 2.000e+00 3.140e+00 1.570e+00 1.310e+00\n",
            " 2.100e+00 1.410e+00 9.100e-01 1.990e+00 1.390e+00 1.150e+00 9.200e-01\n",
            " 2.400e-01 1.510e+00 1.400e-01 1.290e+00 2.390e+00 1.050e+00 5.000e-01\n",
            " 1.790e+00 5.800e-01 1.270e+00 1.340e+00 1.020e+00 2.270e+00 2.550e+00\n",
            " 2.790e+00 4.400e-01 4.800e-01 2.700e-01 2.100e-01 5.100e-01 1.500e+00\n",
            " 1.520e+00 4.000e-02 1.280e+00 1.550e+00 2.120e+00 2.800e-01 8.900e-01\n",
            " 1.960e+00 7.600e-01 1.170e+00 4.900e-01 1.610e+00 1.140e+00 6.500e-01\n",
            " 1.440e+00 1.930e+00 1.370e+00 1.400e+00 8.800e-01 7.300e-01 1.220e+00\n",
            " 1.130e+00 8.100e-01 9.700e-01 1.800e+00 1.090e+00 6.800e-01 1.420e+00\n",
            " 6.700e-01 2.400e+00 1.330e+00 1.210e+00 1.660e+00 9.400e-01 3.900e-01\n",
            " 3.800e-01 1.010e+00 1.070e+00 1.590e+00 1.900e-01 2.110e+00 3.000e-01\n",
            " 1.000e-01 7.200e-01 8.700e-01 5.600e-01 1.600e-01 8.600e-01 6.200e-01\n",
            " 1.000e+00 8.200e-01 8.400e-01 6.400e-01 8.000e-01 4.700e-01 3.200e-01\n",
            " 7.100e-01 1.850e+00 2.430e+00 5.500e-01 5.300e-01 9.000e-02 1.190e+00\n",
            " 7.000e-02 2.000e-01 7.000e-01 2.200e-01 2.900e-01 1.700e-01 5.400e-01\n",
            " 3.600e-01 3.100e-01 5.200e-01 1.100e-01 1.200e-01 1.100e+00 4.600e-01\n",
            " 8.000e-02 5.900e-01 2.300e-01 7.800e-01 2.000e-02 8.500e-01 3.400e-01\n",
            " 2.500e-01 1.800e-01 1.490e+00 1.500e-01 1.300e-01 9.000e-01 4.100e-01\n",
            " 3.000e-02 3.700e-01 5.000e-02 3.300e-01 4.200e-01 6.000e-02 9.500e-01\n",
            " 1.230e+00 6.600e-01 4.300e-01 3.500e-01]\n",
            "JP_Sales [3.770e+00 6.810e+00 3.790e+00 3.280e+00 1.022e+01 4.220e+00 6.500e+00\n",
            " 2.930e+00 4.700e+00 2.800e-01 1.930e+00 4.130e+00 7.200e+00 3.600e+00\n",
            " 2.530e+00 2.400e-01 9.700e-01 4.100e-01 3.540e+00 4.160e+00 6.040e+00\n",
            " 4.180e+00 3.840e+00 6.000e-02 4.700e-01 5.380e+00 5.650e+00 5.320e+00\n",
            " 1.870e+00 1.300e-01 3.120e+00 1.100e-01 4.340e+00 3.500e-01 6.500e-01\n",
            " 7.000e-02 8.000e-02 4.900e-01 3.000e-01 2.660e+00 4.800e-01 5.330e+00\n",
            " 2.670e+00 3.600e-01 3.960e+00 1.910e+00 1.100e+00 1.200e+00 3.080e+00\n",
            " 2.690e+00 1.400e-01 2.540e+00 2.130e+00 8.100e-01 3.800e-01 4.400e-01\n",
            " 2.120e+00 3.150e+00 1.250e+00 0.000e+00 4.000e-02 2.230e+00 2.470e+00\n",
            " 1.000e-02 1.690e+00 3.000e+00 2.000e-02 4.360e+00 1.980e+00 1.000e-01\n",
            " 3.810e+00 2.490e+00 5.000e-02 1.580e+00 3.140e+00 6.600e-01 2.730e+00\n",
            " 3.630e+00 9.800e-01 2.200e-01 1.450e+00 1.310e+00 7.000e-01 2.420e+00\n",
            " 6.000e-01 1.400e+00 1.420e+00 1.390e+00 1.270e+00 8.700e-01 1.700e-01\n",
            " 1.900e-01 9.400e-01 2.100e-01 1.600e+00 1.030e+00 2.500e-01 1.600e-01\n",
            " 2.060e+00 1.490e+00 1.290e+00 9.000e-02 2.870e+00 3.000e-02 8.300e-01\n",
            " 7.800e-01 2.330e+00 4.350e+00 2.020e+00 1.360e+00 1.810e+00 1.970e+00\n",
            " 9.100e-01 9.900e-01 9.500e-01 2.000e+00 1.010e+00 2.780e+00 2.110e+00\n",
            " 1.090e+00 2.000e-01 3.610e+00 1.570e+00 2.200e+00 1.890e+00 1.700e+00\n",
            " 1.080e+00 1.500e-01 1.110e+00 8.000e-01 2.900e-01 1.540e+00 1.200e-01\n",
            " 8.900e-01 4.870e+00 1.520e+00 1.320e+00 1.150e+00 1.440e+00 4.100e+00\n",
            " 4.600e-01 1.050e+00 1.610e+00 2.600e-01 1.380e+00 7.200e-01 6.200e-01\n",
            " 1.800e-01 5.700e-01 5.800e-01 3.100e-01 1.760e+00 3.700e-01 2.100e+00\n",
            " 9.000e-01 5.100e-01 6.400e-01 2.460e+00 9.200e-01 1.070e+00 2.620e+00\n",
            " 1.120e+00 5.400e-01 7.300e-01 2.700e-01 5.900e-01 3.670e+00 5.500e-01\n",
            " 4.000e-01 1.750e+00 3.440e+00 3.300e-01 2.550e+00 7.400e-01 8.200e-01\n",
            " 2.320e+00 7.600e-01 7.700e-01 3.180e+00 2.350e+00 3.190e+00 9.300e-01\n",
            " 8.800e-01 3.030e+00 4.500e-01 1.160e+00 1.190e+00 3.400e-01 1.130e+00\n",
            " 6.800e-01 1.960e+00 7.100e-01 1.040e+00 2.680e+00 2.650e+00 9.600e-01\n",
            " 2.410e+00 5.200e-01 2.430e+00 1.340e+00 1.480e+00 2.340e+00 1.060e+00\n",
            " 1.210e+00 2.280e+00 1.630e+00 2.050e+00 2.170e+00 1.560e+00 1.350e+00\n",
            " 6.300e-01 7.500e-01 7.900e-01 5.300e-01 1.530e+00 1.300e+00 1.460e+00\n",
            " 1.330e+00 3.900e-01 6.900e-01 4.200e-01 5.600e-01 8.400e-01 3.200e-01\n",
            " 1.710e+00 1.650e+00 6.100e-01 1.510e+00 1.500e+00 1.240e+00 1.180e+00\n",
            " 1.370e+00 1.000e+00 1.260e+00 4.300e-01 8.500e-01 1.280e+00 6.700e-01\n",
            " 1.140e+00 8.600e-01 1.170e+00 5.000e-01 1.020e+00 2.300e-01]\n",
            "Global_Sales [8.274e+01 4.024e+01 3.582e+01 3.300e+01 3.137e+01 3.026e+01 3.001e+01\n",
            " 2.902e+01 2.862e+01 2.831e+01 2.476e+01 2.342e+01 2.310e+01 2.272e+01\n",
            " 2.200e+01 2.182e+01 2.140e+01 2.081e+01 2.061e+01 2.022e+01 1.836e+01\n",
            " 1.814e+01 1.728e+01 1.638e+01 1.615e+01 1.585e+01 1.532e+01 1.530e+01\n",
            " 1.498e+01 1.476e+01 1.464e+01 1.435e+01 1.424e+01 1.403e+01 1.373e+01\n",
            " 1.351e+01 1.346e+01 1.310e+01 1.304e+01 1.273e+01 1.227e+01 1.221e+01\n",
            " 1.214e+01 1.198e+01 1.190e+01 1.189e+01 1.166e+01 1.152e+01 1.133e+01\n",
            " 1.118e+01 1.102e+01 1.095e+01 1.079e+01 1.077e+01 1.069e+01 1.057e+01\n",
            " 1.055e+01 1.049e+01 1.042e+01 1.026e+01 1.021e+01 9.880e+00 9.870e+00\n",
            " 9.820e+00 9.760e+00 9.720e+00 9.590e+00 9.520e+00 9.490e+00 9.320e+00\n",
            " 9.300e+00 9.200e+00 9.090e+00 9.020e+00 8.840e+00 8.760e+00 8.490e+00\n",
            " 8.420e+00 8.330e+00 8.240e+00 8.110e+00 8.090e+00 8.060e+00 8.050e+00\n",
            " 7.860e+00 7.840e+00 7.810e+00 7.720e+00 7.690e+00 7.670e+00 7.600e+00\n",
            " 7.580e+00 7.460e+00 7.450e+00 7.370e+00 7.340e+00 7.310e+00 7.300e+00\n",
            " 7.270e+00 7.230e+00 7.200e+00 7.160e+00 7.130e+00 7.070e+00 6.960e+00\n",
            " 6.950e+00 6.910e+00 6.900e+00 6.830e+00 6.820e+00 6.810e+00 6.760e+00\n",
            " 6.730e+00 6.720e+00 6.690e+00 6.670e+00 6.600e+00 6.590e+00 6.560e+00\n",
            " 6.510e+00 6.500e+00 6.430e+00 6.410e+00 6.400e+00 6.390e+00 6.360e+00\n",
            " 6.340e+00 6.310e+00 6.300e+00 6.280e+00 6.270e+00 6.240e+00 6.110e+00\n",
            " 6.050e+00 6.030e+00 5.990e+00 5.950e+00 5.920e+00 5.840e+00 5.830e+00\n",
            " 5.820e+00 5.740e+00 5.720e+00 5.650e+00 5.580e+00 5.570e+00 5.550e+00\n",
            " 5.530e+00 5.510e+00 5.500e+00 5.490e+00 5.470e+00 5.460e+00 5.450e+00\n",
            " 5.430e+00 5.420e+00 5.360e+00 5.340e+00 5.310e+00 5.300e+00 5.290e+00\n",
            " 5.270e+00 5.260e+00 5.240e+00 5.230e+00 5.210e+00 5.200e+00 5.190e+00\n",
            " 5.180e+00 5.170e+00 5.150e+00 5.140e+00 5.130e+00 5.120e+00 5.110e+00\n",
            " 5.080e+00 5.070e+00 5.050e+00 5.020e+00 5.010e+00 5.000e+00 4.980e+00\n",
            " 4.960e+00 4.940e+00 4.910e+00 4.900e+00 4.880e+00 4.870e+00 4.850e+00\n",
            " 4.840e+00 4.830e+00 4.820e+00 4.790e+00 4.770e+00 4.760e+00 4.730e+00\n",
            " 4.700e+00 4.680e+00 4.670e+00 4.640e+00 4.630e+00 4.620e+00 4.610e+00\n",
            " 4.600e+00 4.580e+00 4.570e+00 4.550e+00 4.530e+00 4.500e+00 4.490e+00\n",
            " 4.480e+00 4.470e+00 4.450e+00 4.440e+00 4.420e+00 4.410e+00 4.390e+00\n",
            " 4.380e+00 4.370e+00 4.350e+00 4.340e+00 4.330e+00 4.310e+00 4.260e+00\n",
            " 4.250e+00 4.240e+00 4.230e+00 4.220e+00 4.210e+00 4.200e+00 4.190e+00\n",
            " 4.170e+00 4.160e+00 4.140e+00 4.120e+00 4.110e+00 4.100e+00 4.090e+00\n",
            " 4.080e+00 4.070e+00 4.060e+00 4.050e+00 4.030e+00 4.020e+00 4.010e+00\n",
            " 4.000e+00 3.990e+00 3.980e+00 3.920e+00 3.910e+00 3.900e+00 3.890e+00\n",
            " 3.880e+00 3.870e+00 3.850e+00 3.840e+00 3.830e+00 3.820e+00 3.810e+00\n",
            " 3.790e+00 3.780e+00 3.770e+00 3.760e+00 3.730e+00 3.720e+00 3.710e+00\n",
            " 3.700e+00 3.690e+00 3.670e+00 3.660e+00 3.650e+00 3.640e+00 3.630e+00\n",
            " 3.620e+00 3.610e+00 3.600e+00 3.590e+00 3.580e+00 3.560e+00 3.540e+00\n",
            " 3.530e+00 3.520e+00 3.510e+00 3.500e+00 3.490e+00 3.480e+00 3.460e+00\n",
            " 3.450e+00 3.440e+00 3.430e+00 3.420e+00 3.410e+00 3.400e+00 3.390e+00\n",
            " 3.380e+00 3.360e+00 3.340e+00 3.330e+00 3.320e+00 3.310e+00 3.280e+00\n",
            " 3.270e+00 3.260e+00 3.240e+00 3.230e+00 3.220e+00 3.210e+00 3.200e+00\n",
            " 3.190e+00 3.180e+00 3.170e+00 3.160e+00 3.150e+00 3.140e+00 3.130e+00\n",
            " 3.120e+00 3.110e+00 3.090e+00 3.080e+00 3.070e+00 3.050e+00 3.040e+00\n",
            " 3.030e+00 3.020e+00 3.000e+00 2.990e+00 2.980e+00 2.970e+00 2.960e+00\n",
            " 2.950e+00 2.940e+00 2.930e+00 2.920e+00 2.910e+00 2.900e+00 2.890e+00\n",
            " 2.880e+00 2.870e+00 2.860e+00 2.850e+00 2.840e+00 2.830e+00 2.820e+00\n",
            " 2.810e+00 2.800e+00 2.790e+00 2.780e+00 2.770e+00 2.760e+00 2.750e+00\n",
            " 2.740e+00 2.730e+00 2.720e+00 2.710e+00 2.700e+00 2.690e+00 2.680e+00\n",
            " 2.670e+00 2.660e+00 2.650e+00 2.640e+00 2.630e+00 2.620e+00 2.610e+00\n",
            " 2.600e+00 2.590e+00 2.580e+00 2.570e+00 2.560e+00 2.540e+00 2.530e+00\n",
            " 2.520e+00 2.510e+00 2.500e+00 2.490e+00 2.480e+00 2.470e+00 2.460e+00\n",
            " 2.450e+00 2.440e+00 2.430e+00 2.420e+00 2.410e+00 2.400e+00 2.390e+00\n",
            " 2.380e+00 2.370e+00 2.360e+00 2.350e+00 2.340e+00 2.330e+00 2.320e+00\n",
            " 2.310e+00 2.300e+00 2.290e+00 2.280e+00 2.270e+00 2.260e+00 2.250e+00\n",
            " 2.240e+00 2.230e+00 2.220e+00 2.210e+00 2.200e+00 2.190e+00 2.180e+00\n",
            " 2.170e+00 2.160e+00 2.150e+00 2.140e+00 2.130e+00 2.120e+00 2.110e+00\n",
            " 2.100e+00 2.090e+00 2.080e+00 2.070e+00 2.060e+00 2.050e+00 2.040e+00\n",
            " 2.030e+00 2.020e+00 2.010e+00 2.000e+00 1.990e+00 1.980e+00 1.970e+00\n",
            " 1.960e+00 1.950e+00 1.940e+00 1.930e+00 1.920e+00 1.910e+00 1.900e+00\n",
            " 1.890e+00 1.880e+00 1.870e+00 1.860e+00 1.850e+00 1.840e+00 1.830e+00\n",
            " 1.820e+00 1.810e+00 1.800e+00 1.790e+00 1.780e+00 1.770e+00 1.760e+00\n",
            " 1.750e+00 1.740e+00 1.730e+00 1.720e+00 1.710e+00 1.700e+00 1.690e+00\n",
            " 1.680e+00 1.670e+00 1.660e+00 1.650e+00 1.640e+00 1.630e+00 1.620e+00\n",
            " 1.610e+00 1.600e+00 1.590e+00 1.580e+00 1.570e+00 1.560e+00 1.550e+00\n",
            " 1.540e+00 1.530e+00 1.520e+00 1.510e+00 1.500e+00 1.490e+00 1.480e+00\n",
            " 1.470e+00 1.460e+00 1.450e+00 1.440e+00 1.430e+00 1.420e+00 1.410e+00\n",
            " 1.400e+00 1.390e+00 1.380e+00 1.370e+00 1.360e+00 1.350e+00 1.340e+00\n",
            " 1.330e+00 1.320e+00 1.310e+00 1.300e+00 1.290e+00 1.280e+00 1.270e+00\n",
            " 1.260e+00 1.250e+00 1.240e+00 1.230e+00 1.220e+00 1.210e+00 1.200e+00\n",
            " 1.190e+00 1.180e+00 1.170e+00 1.160e+00 1.150e+00 1.140e+00 1.130e+00\n",
            " 1.120e+00 1.110e+00 1.100e+00 1.090e+00 1.080e+00 1.070e+00 1.060e+00\n",
            " 1.050e+00 1.040e+00 1.030e+00 1.020e+00 1.010e+00 1.000e+00 9.900e-01\n",
            " 9.800e-01 9.700e-01 9.600e-01 9.500e-01 9.400e-01 9.300e-01 9.200e-01\n",
            " 9.100e-01 9.000e-01 8.900e-01 8.800e-01 8.700e-01 8.600e-01 8.500e-01\n",
            " 8.400e-01 8.300e-01 8.200e-01 8.100e-01 8.000e-01 7.900e-01 7.800e-01\n",
            " 7.700e-01 7.600e-01 7.500e-01 7.400e-01 7.300e-01 7.200e-01 7.100e-01\n",
            " 7.000e-01 6.900e-01 6.800e-01 6.700e-01 6.600e-01 6.500e-01 6.400e-01\n",
            " 6.300e-01 6.200e-01 6.100e-01 6.000e-01 5.900e-01 5.800e-01 5.700e-01\n",
            " 5.600e-01 5.500e-01 5.400e-01 5.300e-01 5.200e-01 5.100e-01 5.000e-01\n",
            " 4.900e-01 4.800e-01 4.700e-01 4.600e-01 4.500e-01 4.400e-01 4.300e-01\n",
            " 4.200e-01 4.100e-01 4.000e-01 3.900e-01 3.800e-01 3.700e-01 3.600e-01\n",
            " 3.500e-01 3.400e-01 3.300e-01 3.200e-01 3.100e-01 3.000e-01 2.900e-01\n",
            " 2.800e-01 2.700e-01 2.600e-01 2.500e-01 2.400e-01 2.300e-01 2.200e-01\n",
            " 2.100e-01 2.000e-01 1.900e-01 1.800e-01 1.700e-01 1.600e-01 1.500e-01\n",
            " 1.400e-01 1.300e-01 1.200e-01 1.100e-01 1.000e-01 9.000e-02 8.000e-02\n",
            " 7.000e-02 6.000e-02 5.000e-02 4.000e-02 3.000e-02 2.000e-02 1.000e-02]\n"
          ]
        }
      ],
      "source": [
        "for i in game.columns:\n",
        "    print(i,game[i].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "Rn8eHeVfzoTd",
        "outputId": "a1a20037-bcfc-4564-8821-d56aab339970"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Publisher\n",
              "Unknown    203\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "game[game['Publisher'] == 'Unknown']['Publisher'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "yGtAHaG-zoTd",
        "outputId": "c3ebbcc4-f645-436d-c7f2-d82cfdfab400"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\desktop\\AppData\\Local\\Temp\\ipykernel_18304\\2312479397.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  game.drop(game[game['Publisher'] == 'Unknown'].index, inplace=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Platform</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>NA_Sales</th>\n",
              "      <th>EU_Sales</th>\n",
              "      <th>JP_Sales</th>\n",
              "      <th>Global_Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>41.49</td>\n",
              "      <td>29.02</td>\n",
              "      <td>3.77</td>\n",
              "      <td>82.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>29.08</td>\n",
              "      <td>3.58</td>\n",
              "      <td>6.81</td>\n",
              "      <td>40.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Racing</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>15.85</td>\n",
              "      <td>12.88</td>\n",
              "      <td>3.79</td>\n",
              "      <td>35.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>15.75</td>\n",
              "      <td>11.01</td>\n",
              "      <td>3.28</td>\n",
              "      <td>33.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Role-Playing</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>11.27</td>\n",
              "      <td>8.89</td>\n",
              "      <td>10.22</td>\n",
              "      <td>31.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16593</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Kemco</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16594</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Shooter</td>\n",
              "      <td>Infogrames</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16595</th>\n",
              "      <td>PlayStation</td>\n",
              "      <td>Racing</td>\n",
              "      <td>Activision</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16596</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Puzzle</td>\n",
              "      <td>7G//AMES</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16597</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Wanadoo</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16337 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Platform         Genre   Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
              "0         Nintendo        Sports    Nintendo     41.49     29.02      3.77   \n",
              "1         Nintendo      Platform    Nintendo     29.08      3.58      6.81   \n",
              "2         Nintendo        Racing    Nintendo     15.85     12.88      3.79   \n",
              "3         Nintendo        Sports    Nintendo     15.75     11.01      3.28   \n",
              "4         Nintendo  Role-Playing    Nintendo     11.27      8.89     10.22   \n",
              "...            ...           ...         ...       ...       ...       ...   \n",
              "16593     Nintendo      Platform       Kemco      0.01      0.00      0.00   \n",
              "16594     Nintendo       Shooter  Infogrames      0.01      0.00      0.00   \n",
              "16595  PlayStation        Racing  Activision      0.00      0.00      0.00   \n",
              "16596     Nintendo        Puzzle    7G//AMES      0.00      0.01      0.00   \n",
              "16597     Nintendo      Platform     Wanadoo      0.01      0.00      0.00   \n",
              "\n",
              "       Global_Sales  \n",
              "0             82.74  \n",
              "1             40.24  \n",
              "2             35.82  \n",
              "3             33.00  \n",
              "4             31.37  \n",
              "...             ...  \n",
              "16593          0.01  \n",
              "16594          0.01  \n",
              "16595          0.01  \n",
              "16596          0.01  \n",
              "16597          0.01  \n",
              "\n",
              "[16337 rows x 7 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "game.drop(game[game['Publisher'] == 'Unknown'].index, inplace=True)\n",
        "game"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4yVBUu-30OvK",
        "outputId": "2335bff6-4817-4325-b13f-a6c180c392e9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Platform</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>NA_Sales</th>\n",
              "      <th>EU_Sales</th>\n",
              "      <th>JP_Sales</th>\n",
              "      <th>Global_Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>41.49</td>\n",
              "      <td>29.02</td>\n",
              "      <td>3.77</td>\n",
              "      <td>82.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>29.08</td>\n",
              "      <td>3.58</td>\n",
              "      <td>6.81</td>\n",
              "      <td>40.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Racing</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>15.85</td>\n",
              "      <td>12.88</td>\n",
              "      <td>3.79</td>\n",
              "      <td>35.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>15.75</td>\n",
              "      <td>11.01</td>\n",
              "      <td>3.28</td>\n",
              "      <td>33.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Role-Playing</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>11.27</td>\n",
              "      <td>8.89</td>\n",
              "      <td>10.22</td>\n",
              "      <td>31.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16591</th>\n",
              "      <td>Other</td>\n",
              "      <td>Adventure</td>\n",
              "      <td>Ubisoft</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16592</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Simulation</td>\n",
              "      <td>Destineer</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16593</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Kemco</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16594</th>\n",
              "      <td>Nintendo</td>\n",
              "      <td>Shooter</td>\n",
              "      <td>Infogrames</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16595</th>\n",
              "      <td>PlayStation</td>\n",
              "      <td>Racing</td>\n",
              "      <td>Activision</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14672 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Platform         Genre   Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
              "0         Nintendo        Sports    Nintendo     41.49     29.02      3.77   \n",
              "1         Nintendo      Platform    Nintendo     29.08      3.58      6.81   \n",
              "2         Nintendo        Racing    Nintendo     15.85     12.88      3.79   \n",
              "3         Nintendo        Sports    Nintendo     15.75     11.01      3.28   \n",
              "4         Nintendo  Role-Playing    Nintendo     11.27      8.89     10.22   \n",
              "...            ...           ...         ...       ...       ...       ...   \n",
              "16591        Other     Adventure     Ubisoft      0.01      0.00      0.00   \n",
              "16592     Nintendo    Simulation   Destineer      0.01      0.00      0.00   \n",
              "16593     Nintendo      Platform       Kemco      0.01      0.00      0.00   \n",
              "16594     Nintendo       Shooter  Infogrames      0.01      0.00      0.00   \n",
              "16595  PlayStation        Racing  Activision      0.00      0.00      0.00   \n",
              "\n",
              "       Global_Sales  \n",
              "0             82.74  \n",
              "1             40.24  \n",
              "2             35.82  \n",
              "3             33.00  \n",
              "4             31.37  \n",
              "...             ...  \n",
              "16591          0.01  \n",
              "16592          0.01  \n",
              "16593          0.01  \n",
              "16594          0.01  \n",
              "16595          0.01  \n",
              "\n",
              "[14672 rows x 7 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "publisher_count = game['Publisher'].value_counts()\n",
        "popular_publisher = publisher_count[publisher_count > 15].index\n",
        "game_df = game[game['Publisher'].isin(popular_publisher)]\n",
        "game_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "Agv-XCuO4yzW",
        "outputId": "a0db3dca-f91c-469e-ada6-9fff8aea69f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Publisher\n",
              "Electronic Arts                 1351\n",
              "Activision                       975\n",
              "Namco Bandai Games               932\n",
              "Ubisoft                          921\n",
              "Konami Digital Entertainment     832\n",
              "                                ... \n",
              "GSP                               16\n",
              "Hasbro Interactive                16\n",
              "UFO Interactive                   16\n",
              "Imagineer                         16\n",
              "Mastiff                           16\n",
              "Name: count, Length: 110, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "game_df.value_counts('Publisher')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzwT_7IvIv3Q"
      },
      "source": [
        "feature/target 분리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LkPDz8TdIu3J"
      },
      "outputs": [],
      "source": [
        "feature_df=game_df.drop('Platform',axis=1)\n",
        "target_sr=game_df['Platform']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9sCqralGmqX"
      },
      "source": [
        "인코딩\n",
        "- feature: 원 핫 인코딩\n",
        "- target: 라벨 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Mc7HfnCxGpUx"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ZNYVXAh0KbiO",
        "outputId": "926ef185-8b75-4bae-82e7-e66bbc6fd70d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label=LabelEncoder()\n",
        "label.fit(target_sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV3BNuZoKo7I",
        "outputId": "1de79188-56d9-44da-9ac5-553f68ce3faf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 2])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_label=label.transform(target_sr)\n",
        "target_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "gzbUPNNeW57x",
        "outputId": "df74616c-6ca2-4072-ce13-d302fe1578d0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Publisher</th>\n",
              "      <th>NA_Sales</th>\n",
              "      <th>EU_Sales</th>\n",
              "      <th>JP_Sales</th>\n",
              "      <th>Global_Sales</th>\n",
              "      <th>Genre_Action</th>\n",
              "      <th>Genre_Adventure</th>\n",
              "      <th>Genre_Fighting</th>\n",
              "      <th>Genre_Misc</th>\n",
              "      <th>Genre_Platform</th>\n",
              "      <th>Genre_Puzzle</th>\n",
              "      <th>Genre_Racing</th>\n",
              "      <th>Genre_Role-Playing</th>\n",
              "      <th>Genre_Shooter</th>\n",
              "      <th>Genre_Simulation</th>\n",
              "      <th>Genre_Sports</th>\n",
              "      <th>Genre_Strategy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69</td>\n",
              "      <td>41.49</td>\n",
              "      <td>29.02</td>\n",
              "      <td>3.77</td>\n",
              "      <td>82.74</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>29.08</td>\n",
              "      <td>3.58</td>\n",
              "      <td>6.81</td>\n",
              "      <td>40.24</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69</td>\n",
              "      <td>15.85</td>\n",
              "      <td>12.88</td>\n",
              "      <td>3.79</td>\n",
              "      <td>35.82</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>69</td>\n",
              "      <td>15.75</td>\n",
              "      <td>11.01</td>\n",
              "      <td>3.28</td>\n",
              "      <td>33.00</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69</td>\n",
              "      <td>11.27</td>\n",
              "      <td>8.89</td>\n",
              "      <td>10.22</td>\n",
              "      <td>31.37</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16591</th>\n",
              "      <td>102</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16592</th>\n",
              "      <td>27</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16593</th>\n",
              "      <td>52</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16594</th>\n",
              "      <td>46</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16595</th>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14672 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Publisher  NA_Sales  EU_Sales  JP_Sales  Global_Sales  Genre_Action  \\\n",
              "0             69     41.49     29.02      3.77         82.74         False   \n",
              "1             69     29.08      3.58      6.81         40.24         False   \n",
              "2             69     15.85     12.88      3.79         35.82         False   \n",
              "3             69     15.75     11.01      3.28         33.00         False   \n",
              "4             69     11.27      8.89     10.22         31.37         False   \n",
              "...          ...       ...       ...       ...           ...           ...   \n",
              "16591        102      0.01      0.00      0.00          0.01         False   \n",
              "16592         27      0.01      0.00      0.00          0.01         False   \n",
              "16593         52      0.01      0.00      0.00          0.01         False   \n",
              "16594         46      0.01      0.00      0.00          0.01         False   \n",
              "16595          5      0.00      0.00      0.00          0.01         False   \n",
              "\n",
              "       Genre_Adventure  Genre_Fighting  Genre_Misc  Genre_Platform  \\\n",
              "0                False           False       False           False   \n",
              "1                False           False       False            True   \n",
              "2                False           False       False           False   \n",
              "3                False           False       False           False   \n",
              "4                False           False       False           False   \n",
              "...                ...             ...         ...             ...   \n",
              "16591             True           False       False           False   \n",
              "16592            False           False       False           False   \n",
              "16593            False           False       False            True   \n",
              "16594            False           False       False           False   \n",
              "16595            False           False       False           False   \n",
              "\n",
              "       Genre_Puzzle  Genre_Racing  Genre_Role-Playing  Genre_Shooter  \\\n",
              "0             False         False               False          False   \n",
              "1             False         False               False          False   \n",
              "2             False          True               False          False   \n",
              "3             False         False               False          False   \n",
              "4             False         False                True          False   \n",
              "...             ...           ...                 ...            ...   \n",
              "16591         False         False               False          False   \n",
              "16592         False         False               False          False   \n",
              "16593         False         False               False          False   \n",
              "16594         False         False               False           True   \n",
              "16595         False          True               False          False   \n",
              "\n",
              "       Genre_Simulation  Genre_Sports  Genre_Strategy  \n",
              "0                 False          True           False  \n",
              "1                 False         False           False  \n",
              "2                 False         False           False  \n",
              "3                 False          True           False  \n",
              "4                 False         False           False  \n",
              "...                 ...           ...             ...  \n",
              "16591             False         False           False  \n",
              "16592              True         False           False  \n",
              "16593             False         False           False  \n",
              "16594             False         False           False  \n",
              "16595             False         False           False  \n",
              "\n",
              "[14672 rows x 17 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_label=label.fit_transform(feature_df['Publisher'])\n",
        "feature_df['Publisher']=feature_label\n",
        "feature_ohe=pd.get_dummies(feature_df)\n",
        "feature_ohe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "i93zpZS5G5vZ",
        "outputId": "6548b95c-097c-494d-e72e-892ca609dcb2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Publisher</th>\n",
              "      <th>NA_Sales</th>\n",
              "      <th>EU_Sales</th>\n",
              "      <th>JP_Sales</th>\n",
              "      <th>Global_Sales</th>\n",
              "      <th>Genre_Action</th>\n",
              "      <th>Genre_Adventure</th>\n",
              "      <th>Genre_Fighting</th>\n",
              "      <th>Genre_Misc</th>\n",
              "      <th>Genre_Platform</th>\n",
              "      <th>Genre_Puzzle</th>\n",
              "      <th>Genre_Racing</th>\n",
              "      <th>Genre_Role-Playing</th>\n",
              "      <th>Genre_Shooter</th>\n",
              "      <th>Genre_Simulation</th>\n",
              "      <th>Genre_Sports</th>\n",
              "      <th>Genre_Strategy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69</td>\n",
              "      <td>41.49</td>\n",
              "      <td>29.02</td>\n",
              "      <td>3.77</td>\n",
              "      <td>82.74</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>29.08</td>\n",
              "      <td>3.58</td>\n",
              "      <td>6.81</td>\n",
              "      <td>40.24</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69</td>\n",
              "      <td>15.85</td>\n",
              "      <td>12.88</td>\n",
              "      <td>3.79</td>\n",
              "      <td>35.82</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>69</td>\n",
              "      <td>15.75</td>\n",
              "      <td>11.01</td>\n",
              "      <td>3.28</td>\n",
              "      <td>33.00</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69</td>\n",
              "      <td>11.27</td>\n",
              "      <td>8.89</td>\n",
              "      <td>10.22</td>\n",
              "      <td>31.37</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16591</th>\n",
              "      <td>102</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16592</th>\n",
              "      <td>27</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16593</th>\n",
              "      <td>52</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16594</th>\n",
              "      <td>46</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16595</th>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14672 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Publisher  NA_Sales  EU_Sales  JP_Sales  Global_Sales  Genre_Action  \\\n",
              "0             69     41.49     29.02      3.77         82.74         False   \n",
              "1             69     29.08      3.58      6.81         40.24         False   \n",
              "2             69     15.85     12.88      3.79         35.82         False   \n",
              "3             69     15.75     11.01      3.28         33.00         False   \n",
              "4             69     11.27      8.89     10.22         31.37         False   \n",
              "...          ...       ...       ...       ...           ...           ...   \n",
              "16591        102      0.01      0.00      0.00          0.01         False   \n",
              "16592         27      0.01      0.00      0.00          0.01         False   \n",
              "16593         52      0.01      0.00      0.00          0.01         False   \n",
              "16594         46      0.01      0.00      0.00          0.01         False   \n",
              "16595          5      0.00      0.00      0.00          0.01         False   \n",
              "\n",
              "       Genre_Adventure  Genre_Fighting  Genre_Misc  Genre_Platform  \\\n",
              "0                False           False       False           False   \n",
              "1                False           False       False            True   \n",
              "2                False           False       False           False   \n",
              "3                False           False       False           False   \n",
              "4                False           False       False           False   \n",
              "...                ...             ...         ...             ...   \n",
              "16591             True           False       False           False   \n",
              "16592            False           False       False           False   \n",
              "16593            False           False       False            True   \n",
              "16594            False           False       False           False   \n",
              "16595            False           False       False           False   \n",
              "\n",
              "       Genre_Puzzle  Genre_Racing  Genre_Role-Playing  Genre_Shooter  \\\n",
              "0             False         False               False          False   \n",
              "1             False         False               False          False   \n",
              "2             False          True               False          False   \n",
              "3             False         False               False          False   \n",
              "4             False         False                True          False   \n",
              "...             ...           ...                 ...            ...   \n",
              "16591         False         False               False          False   \n",
              "16592         False         False               False          False   \n",
              "16593         False         False               False          False   \n",
              "16594         False         False               False           True   \n",
              "16595         False          True               False          False   \n",
              "\n",
              "       Genre_Simulation  Genre_Sports  Genre_Strategy  \n",
              "0                 False          True           False  \n",
              "1                 False         False           False  \n",
              "2                 False         False           False  \n",
              "3                 False          True           False  \n",
              "4                 False         False           False  \n",
              "...                 ...           ...             ...  \n",
              "16591             False         False           False  \n",
              "16592              True         False           False  \n",
              "16593             False         False           False  \n",
              "16594             False         False           False  \n",
              "16595             False         False           False  \n",
              "\n",
              "[14672 rows x 17 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_ohe=pd.get_dummies(feature_df)\n",
        "feature_ohe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nehAT90yFrRR"
      },
      "source": [
        "학습용 데이터 셋 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EhrEJR4BF5XY"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pt7ymkjpF611"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(feature_ohe,target_label,test_size=0.2,random_state=0,stratify=target_sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFSYOcg9GakQ"
      },
      "source": [
        "학습 진행: 로지스틱 회귀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nW-iqbJ4GLzR"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "Y66K4H8qGfuE",
        "outputId": "dea1a5ab-cbfc-4bfb-84b8-0ceec50ab2c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr=LogisticRegression()\n",
        "lr.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxVEoCADLuAH",
        "outputId": "6ff9829f-88e9-47d9-96d1-abe9f1acf5d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_score: 0.4762716196643095, test_score: 0.4855195911413969\n"
          ]
        }
      ],
      "source": [
        "train_score=lr.score(x_train,y_train)\n",
        "test_score=lr.score(x_test,y_test)\n",
        "\n",
        "print(f'train_score: {train_score}, test_score: {test_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Rmsr42OuL34f"
      },
      "outputs": [],
      "source": [
        "lr_pred=lr.predict(x_test)\n",
        "lr_pred_proba=lr.predict_proba(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6nOwApSkOD5a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvN5lAqjN6yD",
        "outputId": "c850fbe8-da16-4e8d-b185-077db9c27b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:0.486,roc_auc:0.681\n"
          ]
        }
      ],
      "source": [
        "print('accuracy:{0:.3f},roc_auc:{1:.3f}'.format(accuracy_score(y_test,lr_pred),\n",
        "                                                roc_auc_score(y_test,lr_pred_proba,multi_class='ovr')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "uzsZLvVcPW9c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAyBuaw-_ssz",
        "outputId": "c49c605a-8192-4ca2-c1bc-de5bc55f514f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[463,   0, 637,  16],\n",
              "       [ 42,   0, 174,   5],\n",
              "       [211,   0, 938,  18],\n",
              "       [ 82,   0, 325,  24]], dtype=int64)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(y_test, lr_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VITERZTB_t8f",
        "outputId": "e1d9c78c-26ea-4c5f-814f-01e04bc03010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.41      0.48      1116\n",
            "           1       0.00      0.00      0.00       221\n",
            "           2       0.45      0.80      0.58      1167\n",
            "           3       0.38      0.06      0.10       431\n",
            "\n",
            "    accuracy                           0.49      2935\n",
            "   macro avg       0.35      0.32      0.29      2935\n",
            "weighted avg       0.46      0.49      0.43      2935\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "class_report=classification_report(y_test, lr_pred)\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "myfmsVtf_wGi"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7qw9PTFa_zto",
        "outputId": "a33a38e1-86d1-4db6-86d3-e24a202c36ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
            "45 fits failed out of a total of 150.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "c:\\Users\\desktop\\anaconda3\\envs\\ML_38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.52049012 0.52594351 0.53650864 0.49970113 0.49305533        nan\n",
            " 0.52475071        nan        nan 0.49314051 0.52219399 0.52551754\n",
            " 0.53650864 0.49978634 0.49314051        nan 0.52423959        nan\n",
            "        nan 0.49305533 0.5181897  0.52628432 0.53650864 0.49970113\n",
            " 0.49314051        nan 0.52543237        nan        nan 0.49314051\n",
            " 0.52406913 0.5261139  0.53650864 0.49970113 0.49314051        nan\n",
            " 0.52441005        nan        nan 0.49314051 0.52347205 0.52560264\n",
            " 0.53650864 0.49970113 0.49314051        nan 0.52440988        nan\n",
            "        nan 0.49314051]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최적 하이퍼 파라미터: {'C': 560, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg'}, 최적 평균 정확도: 0.537, solver: LogisticRegression(C=560, max_iter=1000, solver='newton-cg')\n"
          ]
        }
      ],
      "source": [
        "params={'penalty':['l2','l1'],\n",
        "        'C':[560,570,580,590,600],\n",
        "        'max_iter':[1000],\n",
        "        'solver':['lbfgs','liblinear','newton-cg','sag','saga']}\n",
        "\n",
        "lr_clf=LogisticRegression()\n",
        "\n",
        "grid_clf=GridSearchCV(lr_clf,param_grid=params,scoring='accuracy',cv=3)\n",
        "grid_clf.fit(x_train,y_train)\n",
        "print('최적 하이퍼 파라미터: {0}, 최적 평균 정확도: {1:.3f}, solver: {2}'.format(grid_clf.best_params_,grid_clf.best_score_,grid_clf.best_estimator_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxpHbVTL_19y",
        "outputId": "9c7fa232-e41d-44f5-d73d-0bc9401d3d77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_score: 0.5385532930050269, test_score: 0.5321976149914821\n"
          ]
        }
      ],
      "source": [
        "lr2=LogisticRegression(C=560,penalty='l2',max_iter=1000,solver='newton-cg')\n",
        "lr2.fit(x_train,y_train)\n",
        "\n",
        "train_score=lr2.score(x_train,y_train)\n",
        "test_score=lr2.score(x_test,y_test)\n",
        "\n",
        "print(f'train_score: {train_score}, test_score: {test_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PfArEpaBigO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ML_38",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
